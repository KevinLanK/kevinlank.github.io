{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"Java中不可变的一般类型 ","slug":"Java中不可变的一般类型","date":"2018-04-21T07:48:11.000Z","updated":"2018-07-15T07:49:11.474Z","comments":true,"path":"2018/04/21/Java中不可变的一般类型/","link":"","permalink":"http://yoursite.com/2018/04/21/Java中不可变的一般类型/","excerpt":"","text":"Java中不可变的一般类型​ 这几天有在读一些关于并发的书，然后在一本书上看到了这么一个描述：在Java中，Integer属于不变对象，也就是对象一旦被创建，就不可能被修改。这段描述是讲Integer的对象，当初始化之后这个对象的内容就不能够改变了，对Integer的操作，都会新建一个对象。 换句话讲，Integer对象与Streing表现出来的性质是一样的。然后了解了一下，发现在Java中，不仅仅是Integer类，Double、Float等类都是不可变的。然后我测试了一下基本类型的不变性。 自动包装​ Java中存在着这么一个机制：int、double、float等都是一些声明变量的关键字，通过这些关键字进行声明的变量，会在实际处理的时候自动封装成为包装器类型。也就是说，int变量会被包装Integer，同理double和float等也会进行相应处理。 不变性的测试​ 在包装器类型中，声明的对象是不可变类型，那么声明的基本数据类型是不是也是不可变的，我测试了一下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class AutoPackageTest &#123; public static void main(String[] args) &#123; integerTest(); longTest(); doubleTest(); floatTest(); &#125; public static void integerTest()&#123; System.out.print(&quot;This is IntegerTest:&quot;); Integer integer = 1; Integer integerU = integer; int a = 1; int b = a; a++;integer++; System.out.print(integer + &quot; &quot;); System.out.print(integerU + &quot; &quot;); System.out.print(a+ &quot; &quot;); System.out.println(b); &#125; public static void longTest()&#123; System.out.print(&quot;This is LongTest:&quot;); Long aLong = 1L; Long aLongU = aLong; long a = 1L; long b = a; aLong++;a++; System.out.print(aLong + &quot; &quot;); System.out.print(aLongU + &quot; &quot;); System.out.print(a+ &quot; &quot;); System.out.println(b); &#125; public static void doubleTest()&#123; System.out.print(&quot;This is DoubleTest:&quot;); Double c = 1D; Double d = c; double a = 1D; double b = a; c++;a++; System.out.print(c + &quot; &quot;); System.out.print(d + &quot; &quot;); System.out.print(a+ &quot; &quot;); System.out.println(b); &#125; public static void floatTest()&#123; System.out.print(&quot;This is FloatTest:&quot;); Float c = 1F; Float d = c; float a = 1; float b = a; c++;a++; System.out.print(c + &quot; &quot;); System.out.print(d + &quot; &quot;); System.out.print(a+ &quot; &quot;); System.out.println(b); &#125;&#125; ​ 运行上述程序，产生的结果是这样的： 也就是说，通过基本数据类型定义的变量，实际上也会产生一个不可变对象，在经过操作之后，也是通过新建一个新的对象来实现的。 所以在实际应用过程中，对基本类型或者自动包装类型加锁的时候，要注意加锁的对象，是不是当前的实例，新建对象的创建可能会造成加锁对象的改变。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"源码解读","slug":"源码解读","permalink":"http://yoursite.com/tags/源码解读/"}]},{"title":"Java中的Concurrent类的实现 ","slug":"Java中的Concurrent类的实现","date":"2018-04-18T07:46:53.000Z","updated":"2018-07-15T07:47:37.156Z","comments":true,"path":"2018/04/18/Java中的Concurrent类的实现/","link":"","permalink":"http://yoursite.com/2018/04/18/Java中的Concurrent类的实现/","excerpt":"","text":"Java中的Concurrent类的实现​ 在Jdk的实现中，对于HashMap的实现是线程非安全的，在大量并发读的情况下，HashMap能够保持线程安全，但是在存在大量写的情况下，HashMap将会出现并发错误，所以JDK实现了ConcurrentHashMap来保证线程安全并且高效的HashMap。 JDK还实现了ConcurrentLinkedQueue来实现在并发中的非阻塞的队列和BlockingQueue的阻塞线程的队列。 HashMap的实现​ 在ConcurrentHashMap讲述之前，先对HashMap的底层实现做一下总结。 HashMap：散列表。在Java中HashMap通过分离链接法来进行实现，也就是通过数组+链表的方法来进行实现。在JDK1.8后，如果有一个散列表某个散列值对应的链表的元素超过一定值，这个对应的链表将会转化为红黑树的实现，这个值默认为8。也就是说，实际上HashMap的实现为数组+链表+红黑树的实现。 在HashMap的实现中，如果HashMap的数组容量不足，也就是散列后超出现有容量大小，将会对数组大小进行扩增，将新的数组大小扩展成为当前状态的两倍，然后将数据重新散列到新的数组上，所以扩容阶段将会消耗很多资源，并且在并发过程中，出现问题的地方就在扩容阶段。 HashMap的get12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; ​ HashMap将会对关键词key进行hash，然后在数组中进行查找到这个值，然后对整个整个链表进行查找查看是否有这个key对应的value。 HashMap的put123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; ​ 首先先判断是否需要扩容，然后根据key的散列查找到数组索引，然后新建节点进行插入，插入过程中分别按照红黑树或者链表的方法进行插入。 ConcurrentHashMap的实现​ 在并发环境下如果同时对HashMap进行写操作，那么HashMap将会导致内部的Entry数据会链表形成环状数据结构，然后Entry的next节点将永远不为空，也就是会产生死循环获取Entry。而如果对写过程进行加锁，那么错误将不会发生，但是会导致在线程竞争激烈的情况下会出现大量线程阻塞的状态，进而导致效率低下。 针对这个问题，ConcurrentHashMap提供了锁分段技术来提高并发访问率。 分段锁也就是对当前线程访问的数组部分进行加锁，而不是对整个数组进行加锁，通过这种方法，实现写入的时候只有部分加锁，而其他部分将允许线程正常访问。 ConcurrentLinkedQueue的实现​ 在普通的队列实现中，在并发环境下，那么两个线程对同一个队列进行push的时候，尾节点指向两个不同的新加入节点，那么将会有一个节点被销毁；如果是两个线程同时对一个元素进行pop操作，也会出现错误。在JDK里面，实现了非阻塞的队列和阻塞队列，非阻塞队列被实心为ConcurrentQueue，阻塞队列实现为BlockingQueue。 在ConcurrentQueue中，采用CAS算法来对队列中的元素进行写操作。并且在队列内部维护两个节点：head节点和tail节点，head节点指向队列的尾节点。 入队列和出队列不同于一般的队列，ConcurrentQueue在入队列和出队列中采用了不一样的方法。在入队列调整tail节点的时候，会首先判断tail节点当前的指向，如果添加的节点为第一个元素，那么head和tail节点中的next都会指向这个节点，在添加非首节点的时候，判断tail的节点中的next节点，如果为空，会将tail节点的next节点设置为添加节点，如果不为空，将tail节点指向添加节点。在出队列的时候，先检查当前的head节点，如果当前head节点指向的节点元素为空，那么表示已经有其他线程将头节点取走，继续判断下一个头节点，直到能够取出当前节点的元素。 BlockingQueue阻塞队列​ 在阻塞队列中对队列的插入和移除操作进行了扩展： 支持阻塞的插入方法：当队列满的时候，队列阻塞插入元素的线程，直到队列不满。支持阻塞的移除方法：当队列为空的时候，获取元素的线程会阻塞直到队列变为非空。 ​ 在JDK7里面，一共提供了7个阻塞队列： ArrayBlockingQueue：由数组结构组成的有界阻塞队列LinkedBlockingQueue：由链表结构组成的有界阻塞队列PriorityBlockingQueue：支持优先级排序的无界阻塞队列DelayQueue：使用优先级队列实现的无界阻塞队列SynchronousQueue：不储存元素的阻塞队列LinkedTransferQueue：由链表结构组成的无界阻塞队列LinkedBlockingDeque：由链表结构组成的双向阻塞队列 ​ 在队列中元素为空的时候，如果有线程想要获取元素，那么将会进行等待，当有其他线程添加元素到队列中的时候，JDK采用了多种不同的模式提醒阻塞线程：Condition、LockSupport的park对线程进行唤醒操作。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"源码解读","slug":"源码解读","permalink":"http://yoursite.com/tags/源码解读/"},{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"可重入锁ReentrantLock和读写锁ReentrantReadWriteLock ","slug":"可重入锁ReentrantLock和读写锁ReentrantReadWriteLock","date":"2018-04-17T07:46:00.000Z","updated":"2018-07-15T07:46:40.422Z","comments":true,"path":"2018/04/17/可重入锁ReentrantLock和读写锁ReentrantReadWriteLock/","link":"","permalink":"http://yoursite.com/2018/04/17/可重入锁ReentrantLock和读写锁ReentrantReadWriteLock/","excerpt":"","text":"可重入锁ReentrantLock和读写锁ReentrantReadWriteLock​ Java中加入了可重入锁的具体实现：ReentrantLock，还有读写锁的实现：ReentrantReadWriteLock。 ReentrantLock的底层实现​ ReentrantLock是维护了一个内部类Sync来实现的，这个内部类Sync继承了AQS，实现了不公平的加锁和解锁。并且实现了NonfairSync和FairSync来实现可重入锁的公平性和非公平性。 ReentrantLock实现可重入获取锁和解锁​ 在ReentrantLock中的Sync中的加锁的实现如下： 12345678910111213141516171819@ReservedStackAccess final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; ​ 在方法nonfairTryAcquire中，先判断当前的共享资源有没有线程已经加锁，如果没有，使用CAS加锁，返回true，如果已经获得了锁，判断获得锁的线程是不是当前线程，如果是，同步状态+1，否则返回错误。如果在加锁过程中采用了超时加锁，那么具体实现是AQS内的实现方法。 ReentrantLock实现解锁的方式如下： 12345678910111213@ReservedStackAccess protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; ​ 如果该锁被获取了n次，那么前n-1次的释放锁会返回false，只有同步状态完全释放了，才能够返回true。该方法把0作为释放条件，同步状态为0的时候才将占有线程设置为null，返回true，表示释放成功。 ReentrantLock实现公平性加锁和非公平性加锁​ 在ReentrantLock的实现中，默认的加锁方法就是非公平性的加锁，也就是说，虽然实现了内部类NonfairSync继承了Sync，但是加锁的方法只是调用了Sync中的加锁方法： 123protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125; ​ 在公平锁的加锁方法里，重新进行了方法的实现： 1234567891011121314151617181920@ReservedStackAccess protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; ​ 公平锁是按照申请顺序来进行加锁的，也就是说是FIFO顺序，所以在方法里面会先判断有没有前驱节点，如果没有前驱节点，那么这个节点就是头节点，可以进行加锁操作，这也就是通过实现AQS来搭建的好处，可以非常清楚的判断当前队列信息。 公平锁的解锁方式跟非公平锁并无区别。设定一个ReentrantLock是公平锁的实现还是非公平锁的实现，可以通过在构造函数中传入boolean变量来决定。 ReentrantLock中的公平锁和非公平锁对比​ 在公平锁中，每一个线程都会得到锁，也就是都能得到运行机会，而在非公平锁中，如果一个线程在使用CAS加锁前恰好有一个其它线程得到了锁，那么这个线程将会加锁失败，而如果足够凑巧，那么非公平锁将会存在饥饿现象。 但是非公平锁与公平锁相比，非公平锁在执行过程中线程切换较少，所以系统的开销更小，保证了更大的吞吐量。 ReentrantReadWriteLock的底层实现​ ReentrantLock或者synchronized方法都属于独占锁，也就是在同一时刻只能有一个线程持有该锁，在ReentrantReadWriteLock中实现了读写锁，也就是在读状态下，允许多个线程同时获取一个锁。 读写锁改进了在大量数据并发访问少量数据写入情况下的并发性能。 同ReentrantLock一样，在读写锁中通过维护一个私有的Sync的类来实现底层方法的构建。通过实现一个ReadLock和一个WriteLock来实现方法的调用。 ReentrantReadWriteLock实现读写状态​ 在底层的内部类Sync的实现里，有这么几个变量和方法： 123456static final int SHARED_SHIFT = 16;static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125; ​ 也就是在ReentrantReadWriteLock中，同步状态是在一个整型变量上通过使用“按位切割使用”来进行读写锁的区分的。在一个32位的变量上，高16位表示的是读状态，低16位表示的是写状态。 读写锁获取读或者写的状态是通过位运算来进行的。假设同步状态为c，c&gt;&gt;&gt;SHARED_SHIFT表示的是读状态(无符号位右移16位)，c&amp;EXCLUSIVE_MASK表示的是写状态(抹去高16位)。 所以，在c不等于0时，当写状态等于0 ，读状态大于0，也就是读锁已经被获取。 ReentrantReadWriteLock中读锁和写锁对于获取释放的实现​ 写锁的获取等同于互斥锁的实现，也就是存在任何获取到锁的线程，这次获取就失败了： 12345678910111213141516171819@ReservedStackAccess protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) &#123; if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; &#125; ​ 从代码中能够看出，在写锁的实现中，是包括可重入锁的实现的，也就是存在一个写的线程多次获取该所，但是因为按位切割使用的方法，在这里存在一个写锁的最大数量限制，当然，如果发生这种情况，大概系统已经宕机了。 读锁是一个共享锁，当且仅当持有锁的线程持有的是写锁时候，读锁的获取才会失败： 1234567891011121314151617181920212223242526272829@ReservedStackAccess protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != LockSupport.getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current); &#125; ​ 在Java6以后，获取读锁的方法中添加了当前线程获取锁的次数，所以实现复杂了许多。 锁降级​ 锁降级是一种线程安全的实现方式，是写锁降级成为读锁。降级锁是在拥有写锁的时候，持有写锁，先获取读锁，然后释放写锁的过程。 这个过程中保证了数据的可见性，如果线程A不获取读锁而是直接释放写锁，如果此时有另外一个线程B获取写锁更改数据，那么线程A无法获取线程B中的数据更新，所以需要先持有读锁，然后阻塞另外线程B，知道A释放读锁之后，B才能够获取写锁进行数据更新。 ​ 写在文章后：前两次次接触位运算的概念也是在JDK的实现中，一次是在LinkedList扩容的时候，通过位运算确定扩容的大小；另一次是JDK中对于折半查找的实现的时候，通过位运算确定中间量的位置大小。然后这里通过位运算确定读和写的状态，忽然发现JDK实现里面可真是喜欢使用位运算。Java怕不是基于位运算编程...","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"源码解读","slug":"源码解读","permalink":"http://yoursite.com/tags/源码解读/"},{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"AQS","slug":"AQS","date":"2018-04-17T07:45:13.000Z","updated":"2018-07-15T07:45:48.755Z","comments":true,"path":"2018/04/17/AQS/","link":"","permalink":"http://yoursite.com/2018/04/17/AQS/","excerpt":"","text":"AQS​ 在Java中，对于锁的默认实现是synchronized实现的加锁和解锁，而在JDK1.5之后Java中实现了ReentrantLock，ReentrantLock是当内置加锁机制不适用的时候，作为一种可以选择的高级功能。 构建ReentrantLock的时候，采用了AQS(AbstractQueuedSynchronized)，也就是队列同步器作为基础框架。 AbstractQueuedSynchronized​ AbstractQueuedSynchronized是一个用来构建缩合同步组件的基础框架，它是一个高度抽象的类，除去ReentrantLock外，ReentrantReadWriteLock和CountDownLatch等一些不同类型的同步组件也是基于AQS实现的。AQS中使用了一个int类型的成员变量来表示同步状态，并且通过内置的FIFO队列来实现资源获取线程的排队动作。 1234567891011state变量： private volatile int state; protected final int getState() &#123; return state; &#125; protected final void setState(int newState) &#123; state = newState; &#125; protected final boolean compareAndSetState(int expect, int update) &#123; return STATE.compareAndSet(this, expect, update); &#125; ​ AQS定义了一个volatile的int类型的表示同步状态变量，提供了同步状态的访问和修改方法： getState():获取当前的同步状态setState(int newState):设置当前的同步状态compareAndSetState(int expect,int update):使用CAS设置当前状态，这种方法能够保证状态的原子性 ​ AQS还提供了可以重写的许多方法以及模板方法： 可重写方法： 方法名称 描述 protected boolean tryAcquire(int arg) 独占式获取同步状态，实现方法查询当前状态并判断同步状态是否符合预期，使用CAS进行同步状态的设置 protected boolean tryRelease(int arg) 独占式释放同步状态，等待获取状态的线程将有机会获取同步状态 protected int tryAcquireShared(int arg) 共享式获得同步状态 protected boolean tryReleaseShared(int arg) 共享式释放同步状态 protected boolean isHeldExclusively() 判断同步器是否在独占模式下被线程占用 模板方法： 方法名称 描述 public final void acquire(int arg) 抢占式获取同步状态 public final void acquireInterruptibly(int arg) 响应中断的抢占式获取同步状态 public final boolean tryAcquireNanos(int arg, long nanosTimeout) 在acquireInterruptibly的基础上加入超时时间，在时间内获取到锁才成功 public final boolean release(int arg) 独占式释放同步状态，当释放成功之后，会唤醒在同步队列中的第一个节点中的线程 public final boolean releaseShared(int arg) 共享式的释放同步状态 public final void acquireShared(int arg) 共享式的获取同步状态，在同一时刻内能够有多个线程获取到同步状态 public final void acquireSharedInterruptibly(int arg) 响应中断的共享获取同步状态 public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) 在响应中断的共享获取同步状态的基础上加入超时时间 public final Collection getSharedQueuedThreads() 获取在同步队列上的线程的集合 同步队列​ AQS通过在内部维护一个同步队列来实现多个线程对同一个资源访问情况下的线程状态。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657AQS中同步队列的实现：static final class Node &#123; static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; final boolean isShared() &#123; return nextWaiter == SHARED; &#125; final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123;&#125; Node(Node nextWaiter) &#123; this.nextWaiter = nextWaiter; THREAD.set(this, Thread.currentThread()); &#125; Node(int waitStatus) &#123; WAITSTATUS.set(this, waitStatus); THREAD.set(this, Thread.currentThread()); &#125; final boolean compareAndSetWaitStatus(int expect, int update) &#123; return WAITSTATUS.compareAndSet(this, expect, update); &#125; final boolean compareAndSetNext(Node expect, Node update) &#123; return NEXT.compareAndSet(this, expect, update); &#125; final void setPrevRelaxed(Node p) &#123; PREV.set(this, p); &#125; private static final VarHandle NEXT; private static final VarHandle PREV; private static final VarHandle THREAD; private static final VarHandle WAITSTATUS; static &#123; try &#123; MethodHandles.Lookup l = MethodHandles.lookup(); NEXT = l.findVarHandle(Node.class, &quot;next&quot;, Node.class); PREV = l.findVarHandle(Node.class, &quot;prev&quot;, Node.class); THREAD = l.findVarHandle(Node.class, &quot;thread&quot;, Thread.class); WAITSTATUS = l.findVarHandle(Node.class, &quot;waitStatus&quot;, int.class); &#125; catch (ReflectiveOperationException e) &#123; throw new Error(e); &#125; &#125; &#125; ​ 在同步队列里面，waitStatus为线程的等待状态，包括了这样几种情况： CANCELLED，值为1，线程从同步队列中取消等待SIGNAL，值为-1，后继节点的线程处于等待状态CONDITION，值为-2，节点等待在Condition上，等待其他线程对Condition的调用，进而进入到同步队列PROPAGATE，值为-3，笑一次共享式同步状态会无条件地被传播下去INITIAL，值为0，表示初始状态 ​ 在同步队列中，包含了两个节点类型的引用：头节点和尾节点。添加尾节点通过CAS添加，只有当前节点符合预期才会添加进去，并且尾节点引用指向队列的尾节点。 同步队列遵循FIFO，也就是先到达同步队列的线程将优先得到同步状态，当头节点释放同步状态之后，将会唤醒在同步队列中等待的下一个节点的线程，并且当后继节点在获取同步状态成功后会把自己设置为头节点。 再同步队列中的线程会采用自旋的方式来判断自己是否能够获取到同步状态，判断的方式是只有判断前驱节点是头节点的情况下才开始自旋获取同步状态，否则节点中的线程将会进入等待状态。并且通过只有前驱节点是头节点，才尝试获取同步状态，只有成功以后才会把自己设置为头节点，这样提供了并发条件下出现竞争的安全。 共享式获取同步状态或者释放同步状态的情况即读写锁的情况：只有在存在读锁或者不上锁的情况下，读锁的申请才会成功，而只有不上锁的时候写锁才能够获取成功。并且在Java中，ReentrantReadWriteLock的实现就是通过AQS来实现的。 在独占式超时获取同步状态的时候，需要判断当前自旋时间是否超过超时等待时间，如果已经超过，那么获取同步状态就不会成功，否则在未超时的时候同获取独占式同步状态。 Codition​ 除去维护一个同步队列，AQS还维护一个Codition（等待队列）来存储等待状态的线程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235public class ConditionObject implements Condition, java.io.Serializable &#123; private static final long serialVersionUID = 1173984872572414699L; private transient Node firstWaiter; private transient Node lastWaiter; public ConditionObject() &#123; &#125; private Node addConditionWaiter() &#123; Node t = lastWaiter; if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &#125; private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &#125; private void doSignalAll(Node first) &#123; lastWaiter = firstWaiter = null; do &#123; Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; &#125; while (first != null); &#125; private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; Node trail = null; while (t != null) &#123; Node next = t.nextWaiter; if (t.waitStatus != Node.CONDITION) &#123; t.nextWaiter = null; if (trail == null) firstWaiter = next; else trail.nextWaiter = next; if (next == null) lastWaiter = trail; &#125; else trail = t; t = next; &#125; &#125; public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); &#125; public final void signalAll() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first); &#125; public final void awaitUninterruptibly() &#123; Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean interrupted = false; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if (Thread.interrupted()) interrupted = true; &#125; if (acquireQueued(node, savedState) || interrupted) selfInterrupt(); &#125; private static final int REINTERRUPT = 1; private static final int THROW_IE = -1; private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0; &#125; private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt(); &#125; public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); final long deadline = System.nanoTime() + nanosTimeout; long initialNanos = nanosTimeout; Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (nanosTimeout &lt;= 0L) &#123; transferAfterCancelledWait(node); break; &#125; if (nanosTimeout &gt; SPIN_FOR_TIMEOUT_THRESHOLD) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); long remaining = deadline - System.nanoTime(); return (remaining &lt;= initialNanos) ? remaining : Long.MIN_VALUE; &#125; public final boolean awaitUntil(Date deadline) throws InterruptedException &#123; long abstime = deadline.getTime(); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (System.currentTimeMillis() &gt;= abstime) &#123; timedout = transferAfterCancelledWait(node); break; &#125; LockSupport.parkUntil(this, abstime); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; &#125; public final boolean await(long time, TimeUnit unit) throws InterruptedException &#123; long nanosTimeout = unit.toNanos(time); if (Thread.interrupted()) throw new InterruptedException(); final long deadline = System.nanoTime() + nanosTimeout; Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (nanosTimeout &lt;= 0L) &#123; timedout = transferAfterCancelledWait(node); break; &#125; if (nanosTimeout &gt; SPIN_FOR_TIMEOUT_THRESHOLD) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; &#125; final boolean isOwnedBy(AbstractQueuedSynchronizer sync) &#123; return sync == AbstractQueuedSynchronizer.this; &#125; protected final boolean hasWaiters() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) return true; &#125; return false; &#125; protected final int getWaitQueueLength() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int n = 0; for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) ++n; &#125; return n; &#125; protected final Collection&lt;Thread&gt; getWaitingThreads() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); ArrayList&lt;Thread&gt; list = new ArrayList&lt;&gt;(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) &#123; Thread t = w.thread; if (t != null) list.add(t); &#125; &#125; return list; &#125; &#125; ​ 等待队列也是一个FIFO队列，在每个节点上包括了一个线程的引用，这个引用是在Codition对象上等待的线程，当有一个线程调用了Codition对象的await()方法，那么这个线程将会释放锁，构造更节点并且进入等待队列。 跟同步队列不同的是，在等待队列中，每个节点只是存储下一个节点的引用，而不存储前驱节点的引用。添加一个尾节点需要将当前尾节点的引用指向添加节点，并且在Condition里将尾节点修改。更新过程是由锁保证的，并不需要CAS进行更新。 当调用Codition的signal()方法时，会在唤醒首节点前，将节点移到同步队列。而调用signalAll()方法会将整个等待队列中的节点移到同步队列中。 Codition和Object的监视器模型​ 在Object中，存在默认的监视器，即wait()、notify()和notifyALl()方法构成。在监视器模型中。一个对象拥有一个同步队列和等待队列，而在AQS中，可以拥有一个同步队列和多个等待队列，通过这种方式将等待的线程可以按照条件进行区分，即不满足不同条件的线程存储在不同的等待队列中。并且Codition可以精确的控制多个线程的休眠和唤醒。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"源码解读","slug":"源码解读","permalink":"http://yoursite.com/tags/源码解读/"},{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"TCP连接的建立与关闭","slug":"TCP连接的建立与关闭","date":"2018-04-16T07:42:37.000Z","updated":"2018-07-15T07:44:11.679Z","comments":true,"path":"2018/04/16/TCP连接的建立与关闭/","link":"","permalink":"http://yoursite.com/2018/04/16/TCP连接的建立与关闭/","excerpt":"","text":"TCP连接的建立与关闭​ 今天在某个技术群里水群的时候，忽然看到一个有意思的比较有意思的问题：HTTP请求中的TCP连接是由谁来关闭的，服务端还是客户端？然后追问了一下，实际表达的意思是在一个TCP连接中，发出第一个关闭请求的是服务端还是客户端？有什么场景会出现服务端先关闭的情况。 然后今天有空的时候抓了一下包，来专门测试了一下这种情况。 TCP连接的全双工性​ TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议。 首先要明确的一个概念是TCP的连接是基于全双工连接的，也就是说在同一时刻通信的两方能够进行两个方向上的双向传输。明确了这个概念之后再来考虑TCP连接关闭的情况。 TCP连接的建立–三次挥手​ 在TCP建立连接的开始，显示客户端发送一个报文段，来向服务端发起连接请求，并将TCP报文首部的SYN字段设置为1. 第二步是服务器主机发送一个ACK报文段来确认TCP的连接允许，这个ACK报文段中SYN比特仍然被设置为1. 最后一步是客户端发出的对于服务端发送的连接允许的ACK确认，用来确认已经接收到服务端主机的报文，这一步中将SYN设置为0。 TCP连接的关闭–四次挥手​ 在标准的模式中，TCP关闭连接首先是由客户端发出一个含有FIN比特并且设置为1的报文段，用来通知服务端将要关闭连接。 随后服务端向客户端发送一个ACK报文，执行被动关闭。 一段时间后接收FIN报文段的服务端一端将会调用close关闭套接字，TCP将发送一个FIN。 接收最终FIN的端，即最早发送FIN的客户端端将会发送一个ACK确认。 上面提到的TCP连接关闭是标准状态的连接关闭，也就是由客户端申请的关闭连接。 实际抓包测试​ 在下午的时候，我抓了一下在TCP连接的建立和关闭过程中的TCP数据包，查了一下在关闭的时候究竟怎么关闭的情况。然后发现两种情况都是可能出现的，也就是说存在服务器主动发起关闭连接的情况和客户端主动发起关闭连接的情况。在测试用例前，我先ping了一下 www.baidu.com， 得到了百度的ip119.75.213.61。 TCP连接的抓包测试 我是通过在已经开启的浏览器中，打开新建标签页访问119.75.213.61对百度进行连接的方式打开的。能够很清楚的看到在TCP开始时共有三个TCP包，分别承载SYN和ACK来建立连接。 当TCP成功建立连接，浏览器将会发送一条HTTP指令，申请服务器资源访问：GET / HTTP/1.1。 之后的传输是将服务器的资源传输到浏览器上。 TCP保证连接存活的机制​ 在发送第一个HTTP请求的时候，在报文段头部包含了一些HTTP的设置，其中通过对Connection的设置，来进行持续连接的设置。 将Connection设置为keep-alive来确保打开的连接是一个持续连接，也就是请求完一个对象之后不关闭连接。 在连接开启过程中，探测到我的主机周期性的向服务端发送TCP Keep-Alive报文，并且等待服务端的确认来确保TCP连接的开启。 客户端主动关闭TCP连接​ 这篇文章的主要目的是为了讨论客户端或者服务端主动关闭TCP连接的情况，然后抓包测试过程中，我发现仅通过在浏览器对百度的请求条件下就能够进行这两种测试。 第一种条件是我主动关闭浏览器，然后我这边将会向服务端发送FIN报文，这种状况就是正常的TCP连接关闭的状态。 在整个关闭过程中，浏览器发送第一个FIN包:Seq=345 ACK=31994，服务端接收并且发送一个ACK报文:Seq=31994 ACK=346。然后紧接着服务端发送一个对于服务端关闭连接的FIN报文，在这里能够看到的是服务端对这个报文的改变是刚刚传输的ACK报文段中修改了FIN状态：Seq=31994 ACK=346，浏览器接收到这个报文段，然后发送一个确认ACK：Seq=346 ACK=31995。连接就正式关闭了。 在这整个过程中能看到的是发起关闭连接申请的是浏览器，服务器对其进行相应。 服务端主动关闭连接​ 在关闭状态还存在一种非常奇妙的情况，也就是服务端主动关闭连接。 上一个测试例子，我是访问百度之直接关闭浏览器，在这一种情况下，我关闭的仅仅是标签页，也就是浏览器仍然开启，TCP连接建立和前期传输两者间并没有区别。 服务端是在60s左右对我发送了一个FIN报文，但是，实际上我在41s左右的时刻就已经关闭了标签页了，也就是说，在我关闭标签页之后，浏览器仍然维持着这一条TCP连接，知道服务器检测到我长久不使用这个连接，才开始发送报文将连接关闭。 在这种情况的时候，服务端会发送一个FIN报文段：Seq=32039 Ack=356，然后浏览器对这个报文段进行相应，发送一个FIN的报文段：Seq=356 Ack=32040，等服务器接收到之后，会发送一个ACK报文段：Seq=32040 Ack=357，连接关闭，当然这里关闭的连接，是服务端对客户端的连接，在这个状态出现之后，仍然能够看到浏览器向服务端发送的一些保持TCP连接的报文。 所以，在服务端主动关闭TCP连接的情况下，TCP的关闭阶段只会进行三次包的传输，因为要保证用户可能存在的继续使用连接的情况，所以服务端不会向用户发送关闭确认的ACK，而是继续保持该连接一段时间，当达到某段时间后，如果依然没有进行过TCP的相应，那么服务端会直接发送RST报文段，将连接复原。 在整理这篇文章的时候，忽然考虑到服务端是怎样检测浏览器已经关闭了标签页的，然后打开了一个百度的页面进行测试。结果发现，哪怕是没有关闭标签页，持续开启百度页面，服务器依然会在一定时间后向我的浏览器发送FIN报文，然后进入上述状态，直到发送RST报文复原TCP连接。这样之后会在我再次访问当前百度页面的时候进行重新的TCP连接。这个状态是与我是否关闭标签页没关系的，只要浏览器不关闭，这个打开的TCP连接只会在超时未响应或者重复开启TCP连接的时候进行复原，而这个超时连接时间应该是服务端进行设置的。","categories":[],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://yoursite.com/tags/计算机网络/"},{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://yoursite.com/tags/TCP-IP/"}]},{"title":"偏向锁、轻量级锁、重量级锁","slug":"偏向锁、轻量级锁、重量级锁","date":"2018-04-15T07:40:38.000Z","updated":"2018-07-15T07:41:37.602Z","comments":true,"path":"2018/04/15/偏向锁、轻量级锁、重量级锁/","link":"","permalink":"http://yoursite.com/2018/04/15/偏向锁、轻量级锁、重量级锁/","excerpt":"","text":"偏向锁、轻量级锁、重量级锁​ 在讲述Java的偏向锁之前，先对我在《Java中的锁》一文中提到的自旋锁做一下补充，并且总结一下锁在Java对象中的存储。 自旋锁和自适应自旋​ 自旋锁的表示为想要持有锁的线程不断的对能够获取锁的判断条件进行判断，直到能够拿到锁。这个过程中不断地自旋将会带来非常大的CPU消耗，所以这种普通的自旋锁的实现一般是有自旋时间或者次数限制，当到达限制的时候还没有拿到锁，那么将会采取方法把线程挂起。 在JDK1.6中，引入了自适应的自旋锁，也就意味着自旋锁的自旋的次数不再是固定不变的，而是由上一个在同一个锁上的自旋时间以及锁的拥有着的状态来决定的：如果在同一个锁 对象上，自旋等待刚刚成功获得了锁，并且持有锁的线程正在运行中，那么虚拟机会认为这个锁这次自旋也有可能成功，进而将允许自旋等待持续相对时间更长；对于某个锁，如果自旋很少成功获得过，那在以后要获取这个锁将可能省略自旋条件，避免浪费处理器资源。 Mark Word​ 在Java中，synchronized所采用的锁是保存在Java对象头里面的，Java在32位或者64位机器上，对于对象头存储采用的大小是不同的，在32位系统里采用32bit存储，64位系统采用64bit存储。 在32位系统里面，对象头的MarkWord里面有25位存储对象的hashCode，也就是存储对象指向类元数据的指针，有4bit存储对象分代年龄，1bit用来表示是否是偏向锁，2bit来存储锁标志位。 存储内容 标志位 状态 对象哈希码、对象分代年龄 01 未锁定 指向锁记录的指针 00 轻量级锁定 指向重量级锁的指针 10 膨胀（重量级锁定） 空，不需要记录信息 11 GC标记 偏向线程ID、偏向时间戳、对象分代年龄 01 可偏向 偏向锁​ 偏向锁是指一个线程持有锁之后，在对象头和栈帧中规定锁记录里存储锁偏向的线程ID，之后该线程退出或者进入这个锁都将不会进行CAS来加锁或者解锁，只需要测试MarkWord里面的标识。如果测试成功，表示线程已经获得了锁，否则测试一下在MarkWord中偏向锁的标识是否设置为1，没有的话采用CAS竞争锁，已经有了的话将对象头的偏向锁指向当前线程。 如果有两个或者多个线程同时竞争锁的时候或者已经有一个线程持有锁另外一个线程申请获得锁，那么这个时候这个锁膨胀为轻量级锁。 偏向锁的目标是消除数据在无竞争情况下的同步源于，将进一步提高程序的并行性能。 轻量级锁​ 轻量级锁是存在多个线程竞争同一把偏向锁的时候，偏向锁膨胀形成的锁。 在不存在竞争的时候，轻量级锁使用CAS操作进行加锁，因为不使用信号量，所以相对于重量级锁减少了开销，但是当存在竞争的时候，轻量级锁不在有效，将膨胀为重量级锁，等待获取锁的进程将会被阻塞。 在锁竞争的情况下，轻量级锁是可以先通过自旋的方法来获取锁，如果多次获取不成功在将锁膨胀为重量级锁，通过这种方法来减少一定的开销。 重量级锁​ 重量级锁就是通常意义上的互斥锁，重量锁通过将访问竞态条件的其他线程阻塞，来实现在并发的条件下的安全性。 偏向锁、轻量级锁、重量级锁/偏向锁、轻量级锁的状态转","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"},{"name":"锁","slug":"锁","permalink":"http://yoursite.com/tags/锁/"}]},{"title":"Java中的锁 ","slug":"Java中的锁","date":"2018-04-15T07:39:45.000Z","updated":"2018-07-15T07:40:20.778Z","comments":true,"path":"2018/04/15/Java中的锁/","link":"","permalink":"http://yoursite.com/2018/04/15/Java中的锁/","excerpt":"","text":"Java中的锁​ 在《同步语义-synchronized+final》一文中，我提到了Java中的锁–synchronized。synchronized在Java中是内置锁的实现，通过将方法、变量或者对象设为synchronized来实现自动的加锁和解锁步骤。 但是在Java中，还有多种或显式或隐式的锁来实现并发编程，在这里详细的整理一下。 锁的分类​ 在Java里，锁能够按照多种方式区分： 依据线程执行的公平性：公平锁和非公平锁依据能否有多个线程持有同一个锁：共享锁和独占锁、互斥锁和读写锁按照线程加锁的态度：乐观锁和悲观锁依据线程持有锁的程度：偏向锁和轻量级锁和重量级锁除此之外，还有：分段锁、可重入锁、自旋锁、阻塞锁 乐观锁和悲观锁​ 从宏观上讲，锁分为乐观锁和悲观锁。 乐观锁​ 乐观锁对上锁保持一种乐观态度，即认为在线程执行过程中，读多写少，遇到并发写的时间较少，所以采用不加锁的方式，也就是无锁编程。在Java中，实现乐观锁的方式为循环CAS方法，只通过在数据提交时的比对，来判断是否应该进行数据更新。这种方式存在ABA问题，循环时间过长的时候开销大，只能保证一个共享变量的原子操作。乐观锁的一致性比悲观锁差，但是对于种地程度的并发，效率大大提高。 12CAS的实现： compareAndSet(int v, int a); 悲观锁​ 悲观锁对上锁保持悲观态度，即认为在线程执行过程中，写多读少，遇到并发写的时间较多，所以对于每次读写数据的时候都会进行上锁。在Java中，独占锁或synchronized的实现都是悲观锁的实现。悲观锁的安全性高，更适合高并发的情况。 自旋锁​ 自旋锁是指线程A想要获取一个锁，但是这个锁被其他线程持有，所以A通过不断地循环来判断锁是否已经被释放，当前可用。 自旋锁在自旋时候并不会释放CPU，所以持有自旋锁的线程需要尽快的释放锁，以让其他需要占有的线程持有锁，防止不断地自旋消耗CPU资源。而如果持有锁的线程不是尽快释放锁，而是将其他线程堵塞，这种实现是阻塞锁。 持有自旋锁的线程在睡眠前或者任务结束后，应当立即释放锁以便让其他线程能够获得锁。 1234567自旋锁的实现： public void lock() &#123; int myticket = ticketNum.getAndIncrement(); LOCAL.set(myticket); while (myticket != serviceNum.get()) &#123; //在这里还使用了CAS方法 &#125; &#125; 阻塞锁​ 阻塞锁指的是让线程进入阻塞状态进行等待，当获得相应的通知的时候唤醒进程，就绪状态的所有线程通过竞争的方式进入运行状态。 在Java中，重量级锁、ReentrantLock都包含阻塞锁的实现。阻塞锁相对于自旋锁来说，降低了CPU的使用率，但是效率不一定比自旋锁高，因为线程的唤醒进入时间以及回复时间都比自旋锁慢。 在竞争激烈的情况下 阻塞锁的性能要明显高于 自旋锁。理想的情况是; 在线程竞争不激烈的情况下，使用自旋锁，竞争激烈的情况下使用，阻塞锁。 可重入锁​ 可重入锁是指能够重进入的锁，表示一个锁能够支持线程对一个资源的重复加锁。可重入锁有公平锁和非公平锁的实现。 可重入锁中，通过维护一个计数器，来描述持有该锁的线程已经持有了多少次锁，每一次加锁都对应着一次解锁操作。 12345678910111213141516171819可重入锁的实现：final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 公平锁和非公平锁​ 公平性与否是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求的绝对时间顺序，也就是FIFO。而对于非公平锁，只要CAS能够设置同步状态成功，那么表示当前线程获取了锁。 在Java中，ReentrantLock分别实现了公平锁和非公平锁。 12345678910111213公平锁的实现：hasQueuedPredecessors()方法用于检查等待队列中有没有元素。if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true;&#125;非公平锁的实现：if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125;&#125; 共享锁和独占锁​ 独占锁指每次只能有一个线程能够持有锁，ReentrantLock就是以独占方式实现的互斥锁。共享锁，允许读个线程同时持有锁，并发的访问共享资源，ReadWriteLock中的readLock就是一种共享锁的实现。 读写锁​ 读写锁是Java对于处于读和写两种不同状态下的并发提供的一种锁。读写锁维护了两个锁：读锁和写锁，通过分离读锁和写锁，使得并发性相较于其他的独占锁有了提升。读写锁也是可以选择实现公平锁或者非公平锁。 当有一个线程持有读锁的时候，如果有其他线程想要获得锁，那么便能够获得锁，此时维护的是一个共享锁，并且这个共享锁是支持重进入的。如果线程获取读锁的时候，已经有其他线程获取了写锁，那么这个线程将会进入等待状态。而写锁只有在没有任何线程访问的时候才能够获得，实质上是一个排它锁。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950写锁实现：protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; &#125;读锁的实现：protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != LockSupport.getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current); &#125; 分段锁​ 分段锁是在HashMap中的一个实现。HashTable容器在竞争激烈的并发环境中的时候，由于线程会竞争统一把锁，所以会导致效率低下。所以在容器里假设有多把锁，每把锁用于锁容器中的一部分数据，当不同的线程访问不同的数据的时候，就会持有不同的锁，降低了锁竞争的现象，有效的提高并发效率，这种方法就是CurrentHashMap的锁分段技术，将数据分为一段一段的存储，一段数据具有一把锁，一个线程占有一把锁的时候，并不影响其他线程访问其他数据段。 偏向锁、轻量级锁、重量级锁​ 在synchronized一文中，我简单的提到了这三种锁，我将在一篇文章里详细的介绍这三种锁： 偏向锁、轻量级锁、重量级锁","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"},{"name":"锁","slug":"锁","permalink":"http://yoursite.com/tags/锁/"}]},{"title":"Java中的并发 ","slug":"Java中的并发","date":"2018-04-14T07:38:52.000Z","updated":"2018-07-15T07:39:28.585Z","comments":true,"path":"2018/04/14/Java中的并发/","link":"","permalink":"http://yoursite.com/2018/04/14/Java中的并发/","excerpt":"","text":"Java中的并发​ 已经写过一些有关于并发的文章，然后统一整理一下： Java并发模型原理：​ 共享内存模型 内存屏障 volatile synchronized和final 双重检查锁和延迟初始化 线程间通信 Java内存模型 Java中的锁及其实现​ Java中的锁 偏向锁、轻量级锁、重量级锁 AQS的实现 可重入锁和读写锁 Java中Concurrent类的实现 初步接触并发，若有错误，还请雅正。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"},{"name":"文章整理","slug":"文章整理","permalink":"http://yoursite.com/tags/文章整理/"}]},{"title":"Java内存模型","slug":"Java内存模型","date":"2018-04-14T07:36:54.000Z","updated":"2018-07-15T07:37:54.708Z","comments":true,"path":"2018/04/14/Java内存模型/","link":"","permalink":"http://yoursite.com/2018/04/14/Java内存模型/","excerpt":"","text":"Java内存模型​ 在之前的一些有关并发的文章里面，掺杂着各种JMM有关的知识点，在这里加入JVM的内存统一整理一下。 Java内存区域​ 在《深入理解JVM》一书中，对Java的内存区域（运行时数据区）进行了比较明确的划分： 虚拟机栈 虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时会创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。常说的Java栈指的就是在Java虚拟机栈中的局部变量表部分。局部变量表部分存储一直的基本数据类型对象引用和returnAddress类型。在虚拟机栈中可能出现的错误： 线程请求的栈深度大于虚拟机允许的深度，抛出StackOverFlowError异常。扩展时无法申请到足够的内存，抛出OutOfMemoryError异常。 本地方法栈 本地方法栈为虚拟机使用的Native方法进行服务，其他的基本类似于虚拟机栈。在JVM规范中，并没有对本地方发展的具体实现方法以及数据结构作强制规定，虚拟机可以自由实现它。在HotSopt虚拟机中直接就把本地方法栈和Java栈合二为一。 堆 Java堆(Java Heap)是Java虚拟机中管理的内存最大的一块，并且堆被所有的线程共享。堆会存放对象实例，在JVM规范中的描述是：所有的对象实例以及数组都要在堆上分配。Java堆是垃圾收集器管理的主要区域，所以也被称为”GC堆”。还可能存在多种更为细致的划分，目的是更好的回收内存，或者更快的分配内存。在JVM规范中，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的。在堆中可能出现的错误 如果在堆中没有内存完成实例分配，并且堆再也无法扩展时，将会抛出OutOfMemoryError异常。 方法区 方法区跟Java堆一样，是各个线程共享的内存区域，用于存储已经被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区也被称之为Non-Heap(非堆)，用以跟Java堆的区分。在方法区中存在运行时常量池，用来存放编译期生成的各种字面量和符号引用以及存储翻译出来的直接引用，并且运行期常量池是能够在运行过程中进行添加的，比如String类的intern()方法。常量池和运行期常量池辨析 在Class文件中，除了有类的版本、字段、方法、借口等描述信息，还有常量池，常量池存放编译期生成的各种字面量和符号引用，这一部分内容会在类加载后刷入到方法区的运行时常量池中存储。运行期常量池是方法区的一部分，并且能够在运行期间进行添加。 方法区可能出现的错误 当方法区无法满足内存分配时，将会抛出OutOfMemoryError异常。 Java内存模型​ 在Java中，采用的线程通信方式是共享内存模型，所以Java内存模型(Java Memory Model)的实现是通过共享内存的方法进行实现的。Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。 Java的内存模型规定了所有的变量都储存在主内存， 每条线程还有自己的工作过内存，线程的工作内存保存了线程中使用到的主内存副本拷贝，线程的操作是对工作内存的操作，不允许直接操作主内存。并且线程之间的工作内存是互相隔离的，线程间的传递需要通过主内存，这也就是共享内存模型的内容。 除去基本的内存模型，JMM保证了可见性、原子性、有序性。 可见性的概念也就是内存可见性，JMM对于可见性的支持是采用了volatile关键字或者锁来保证可见性。原子性的概念也就是在执行过程中，一个操作是不能够中断的，这之间存在线程之间的共享变量读取写入的问题。在JMM中，采用了synchronized来保证并发过程的安全性和操作的原子性。有序性指的是在指令执行过程中的指令重排序现象，JMM采用了volatile、synchronized、final分别做到了不同的保证，来确保在多线程环境过程中的语义有序性，例如实现happens-before规则和as-if-serial语义。 ​ 上述提到的JMM确保的规则，在其他文章中都有提及，这里不再复述。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"},{"name":"内存模型","slug":"内存模型","permalink":"http://yoursite.com/tags/内存模型/"}]},{"title":"线程间通信","slug":"线程间通信","date":"2018-04-13T07:19:57.000Z","updated":"2018-07-15T07:36:22.627Z","comments":true,"path":"2018/04/13/线程间通信/","link":"","permalink":"http://yoursite.com/2018/04/13/线程间通信/","excerpt":"","text":"线程间通信​ 我在《同步语义-volatile》一文中提到过共享内存和消息传递线程中的两种通信机制，但是在Java线程中的通信方式存在很多种，在这里整理了一下。 共享内存​ 通过设置共享变量，多个进程来访问共享变量，从而隐式的达到线程间的通信。 等待/通知机制​ 是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而执行后续操作。等待/通知机制是一种很典型的消息传递的机制。 经典范例 等待方 获取对象的锁如果条件不满足，调用对象的wait()方法，被通知后仍要检查条件条件满足执行对应逻辑 伪代码synchronized(对象) { while(条件不满足) { 对象.wait(); } 对应的处理逻辑} 通知方 获得对象的锁改变条件通知所有等待在对象上的线程 伪代码synchronized(对象) { 改变条件 对象.notifyAll(); 管道​ 管道输入/输出和普通的文件输入/输出流或者网络输入/输出流不同之处在于它用于线程之间的数据传输，传输媒介为内存。 同步​ 在Java中，线程之间的同步也就是通过volatile和synchronized关键字来进行数据同步。","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"},{"name":"线程通信","slug":"线程通信","permalink":"http://yoursite.com/tags/线程通信/"}]},{"title":"双重检查锁和延迟初始化","slug":"双重检查锁和延迟初始化","date":"2018-04-13T07:19:48.000Z","updated":"2018-07-15T07:35:37.763Z","comments":true,"path":"2018/04/13/双重检查锁和延迟初始化/","link":"","permalink":"http://yoursite.com/2018/04/13/双重检查锁和延迟初始化/","excerpt":"","text":"双重检查锁和延迟初始化​ 有幸听一位学长讲过一次关于Java中单例模式与静态成员初始化对比的一个知识点。第一个知识点是在完成一个final域的初始化之前，存在着能够读取值的可能性；第二个知识点是在并发中，对于单例模式的一种可以称作为优化设计的知识。恰巧学到了这些内容的知识点，重新读了一下内容，整理了一下。 final初始化的一种读值可能性​ 在《同步语义-synchronized+final》一文中，我描述过一种在并发过程中读取未正常初始化的final域的现象，也就是在构造函数中this引用逸出，导致指令重排序之后第二个线程在final域写入值前读取到了这个对象。当然，这是一种完全可以避免的操作，只要没有this逸出，那么JMM就会保证这个错误不会发生。 final在另外一种情况下可能存在读取未初始化值的情况，是这样的： 12345678910111213141516171819public class Elvis &#123; public static final Elvis INSTANCE = new Elvis(); private final int beltSize; static final int CURRENT_YEAR = Calendar.getInstance().get(Calendar.YEAR); private Elvis() &#123; beltSize = CURRENT_YEAR - 1930; &#125; public int beltSize() &#123; return beltSize; &#125; public static void main(String[] args) &#123; System.out.println(&quot;Elvis wears a size &quot; + INSTANCE.beltSize() + &quot; belt.&quot;); System.out.println(INSTANCE.CURRENT_YEAR); &#125;&#125;输出：Elvis wears a size -1930 belt.2018来源：《Java解惑》 ​ 如果初始化是正常的，那么这个程序的答案应该是2018-1930，但是在输出中，第一步的输出的数字是-1930，而INSTANCE.CURRENT_YEAR的值却是2018。 问题出现在，构造器会用一个涉及静态域的CURRENT_YEAR来初始化beltSize，在JAVA中，初始化静态域会造成调用类的构造器来初始化，但是这个过程已经处在初始化过程中了，那么CURRENT_YEAR的值将设置为默认值，然后用来初始化beltSize，在之后才将CURRENT_YEAR进行初始化，当然已经不再起作用了。 所以： 在final类型的静态域被初始化之前，存在着读取其值的可能性final类型的域只有在其初始化表达式是常量表达式才是常量 ​ 对于这个问题，书中给出了建议： 想改正一个类初始化循环，需要重新对静态域的初始器进行排序，使得任何一个初始器都出现在任何依赖于它的初始器之前。 延迟初始化​ 在涉及双重检查锁和单例模式之前，先对延迟初始化的概念进行一下总结。 在Java中，有的时候需要采用延迟初始化来降低初始化类和创建对象的开销，也就是说，只有在需要某个对象的时候才对这个对象进行初始化。 12345678public class UnsafeLazyInitialization &#123; private static Instance instance; public static Instance getInstance() &#123; if (instance == null) //操作1 instance = new Instance(); //操作2 return instance; &#125;&#125; 双重检查锁​ 在延迟初始化部分列举的例子，如果是在单线程环境下运行，那么这个不会出现问题。但是如果环境是在多线程环境下，当有两个线程A、B的时候，当A执行操作1，但B执行操作2的时候，因为指令重排序的关系，对象的内存地址已经被分配，但是并没有进行初始化。所以有可能存在A线程看到instance引用的对象还没有完成初始化的现象。 对于这种现象，采用加锁的方法，来进行同步处理实现线程安全的延迟初始化。 12345678public class SafeLazyInitialization &#123; private static Instance instance; public synchronized static Instance getInstance() &#123; if (instance == null) instance = new Instance(); return instance; &#125;&#125; ​ 当有一个线程进行初始化过程的时候，另外的线程访问都会被阻塞，从而保证不会存在错误的初始化访问现象。但是因为每一次有线程访问这段同步代码的时候，都会进行加锁解锁操作，将会导致大量的系统开销。所以，在这个基础上，设计了“双重检查否定”的方法，来降低同步的开销。 123456789101112public class DoubleCheckedLocking &#123; //1 private static Instance instance; //2 public static Instance getInstance() &#123; //3 if (instance == null) &#123; //4:第一次检查 synchronized (DoubleCheckedLocking.class) &#123; //5:加锁 if (instance == null) //6:第二次检查 instance = new Instance(); //7 &#125; //8 &#125; //9 return instance; //10 &#125; //11&#125; //12 ​ 在上述实现里，如果第一次检查instance部位null，那么就不需要执行加锁和初始化操作，从而减少系统开销。 但是，同样的，建立了双重检查锁的方法，同样会造成不存在锁的时候的错误，也就是说，仍然有可能读取未正确初始化的对象。对于这种现象，采用volatile来防止指令重排序，从而保证线程安全。 单例模式​ 单例模式常用的有三种：饿汗式、懒汉式、嵌套类。 在饿汉式模式中，可能会存在上述内容讲到的初始化依赖的现象： 1234567891011public class Singleton&#123; //在自己内部定义自己的一个实例，只供内部调用 private static final Singleton instance = new Singleton(); //可能存在着初始化依赖的现象 private Singleton()&#123; //do something &#125; public static Singleton getInstance()&#123; return instance; &#125;&#125; ​ 在懒汉式模式里，采用了双重检查锁否定的方法，同时将私有对象设置为volatile的，来保证线程安全性： 12345678910111213141516public class Singleton&#123; private static volatile Singleton instance=null; private Singleton()&#123; //do something &#125; public static Singleton getInstance()&#123; if(instance==null)&#123; synchronized(Singleton.class)&#123; if(instance==null)&#123; instance=new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; ​ 嵌套类的模式，是三种方法里比较好的一种，通过这种方法，能够提供类似于饿汉式的线程安全性而不需要加锁增大系统开销，同时因为类加载器的初始化顺序，保证了不会存在静态final域的初始化问题。 1234567public final class Singleton &#123; private static class SingleHolder &#123; private static final Singleton single = new Singleton(); &#125; public static Singleton getSingle() &#123;return SingleHolder.single;&#125; private Singleton() &#123;&#125;&#125;","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"},{"name":"单例","slug":"单例","permalink":"http://yoursite.com/tags/单例/"}]},{"title":"同步语义-synchronized+final","slug":"同步语义-synchronized-final","date":"2018-04-13T07:19:41.000Z","updated":"2018-07-15T07:34:28.747Z","comments":true,"path":"2018/04/13/同步语义-synchronized-final/","link":"","permalink":"http://yoursite.com/2018/04/13/同步语义-synchronized-final/","excerpt":"","text":"同步语义-synchronized+finalJava中的锁–synchronized​ 在并发编程中，synchronized一直是非常重要的角色。通过加锁解锁，让临界区互斥执行，并且释放一个锁的线程向获取同一个锁的线程发送消息。 在上面的示意图中，A线程先进行加锁，然后更新a的值，A释放锁之后，线程A会把a的值刷回到主内存中，当B进行加锁的时候，会从主内存中重新读取数据，此时就拿到了最新的A改变的a的值，也就是在两个线程中间做到了通信。锁的这种通信方式也是JMM所采用的共享内存模型。 在JDK1.6之后，对synchronized的语义进行了优化，让这个锁变的没有那么重量级了。 锁的优化​ 在Java 1.6之后，在Java中，并发的锁有了四种状态：无锁状态、偏向锁、轻量级锁、重量级锁。 在JMM的实现中，无锁状态指的是采用了CAS（CompareAndSet）算法对共享变量进行操作。 CAS 在每次对共享数据进行刷新的时候，传入内存值，旧的预期值和要修改的值，当且仅当内存值和旧的预期值相同时，将这个值修改为要修改的值，否则返回错误。 缺陷 ABA问题。即如果存在两个线程T1和T2，T1使用CAS进行检查，在这期间，T2将数据A先修改到B，再将数据修改回A，T1检查数据是正确的，但是实际上数值已经被修改。循环时间长开销大。只能保证一个共享变量的原子操作。 ​ 三种锁的优劣： 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳米级的消耗的差距 如果线程中存在锁竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问同步块的场景。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度 如果始终得不到锁竞争的线程，使用自旋会消耗CPU 追求响应时间；同步块执行速度非常快 重量级锁 线程竞争不使用自旋，不会消耗CPU 线程阻塞，响应时间缓慢 追求吞吐量；同步块执行速度较长 synchronized在执行互斥代码时的步骤 获得互斥锁清空工作内存拷贝变量的最新副本到工作内存执行代码将更改后的变量的值刷新到主内存释放锁 final语义规则​ 对final域，在编译器和处理器之间遵循两个重排序规则： 在构造函数内对一个final域的写入，与随后把这个构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。 写final域的重排序规则​ JMM禁止编译器把final域的写重排序到构造函数之外。 编译器会在final域的写之后，构造函数return之前，插入StoreStore屏障。这个屏障禁止处理器把final域的写重排序到构造函数之外。 通过上述两个写域的规则，JMM能够确保在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，也就是另外一个线程读到的final域的数据一定是期望的值。 读final域的重排序规则​ 在读final域之前，编译器会在操作前面插入一个LoadLoad屏障。通过这个屏障，JMM可以确保在读一个final域之前，一定会先读包含这个final域的对象的引用。 this逸出​ 在执行对象的构造过程的时候，会存在一种诡异的现象：this逸出。也就是在对象构造过程中，对象的引用在对象未能够构造完成的情况下引用被赋值给其他线程。 12345678910111213141516public class FinalReferenceEscapeExample &#123; final int i; static FinalReferenceEscapeExample obj; public FinalReferenceEscapeExample() &#123; i = 1; //写final域 obj = this; //this引用在这里逸出 &#125; public static void writer() &#123; new FinalReferenceEscapeExample(); &#125; public static void reader() &#123; if (obj != null) &#123; int temp = obj.i; &#125; &#125;&#125; ​ 在上述代码中，当有两个线程A执行的writer()时候，在构造函数内部，如果发生重排序，即对象赋值先于final初始化发生，并且在这个过程中，线程B执行reader()方法，那么读取到的obj将是已经不为null的对象，接着读取到未初始化的final域i，发生错误。 所以在函数构造过程中，要保证在构造函数返回前，被构造对象的引用不能够被其他线程看见。","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"},{"name":"同步语义","slug":"同步语义","permalink":"http://yoursite.com/tags/同步语义/"}]},{"title":"同步语义-volatile","slug":"同步语义-volatile","date":"2018-04-12T07:19:32.000Z","updated":"2018-07-15T07:33:16.575Z","comments":true,"path":"2018/04/12/同步语义-volatile/","link":"","permalink":"http://yoursite.com/2018/04/12/同步语义-volatile/","excerpt":"","text":"同步语义-volatilevolatile是啥​ volatile，在Java中保证了线程之间对于共享变量的同步，这里的同步，是指内存可见性，除去保证内存可见性，volatile语义还对JMM对于指令的重排序进行了禁止。 提到volatile的同步，在线程中通信机制中，有两种方式来完成线程的通信：共享内存和消息传递（actor）。 共享内存： 是通过设置一个共享变量，多个线程来对这个共享变量进行读写操作，在读写过程中，不同的线程读取到的数据可能是其他线程写入的，这样就做到了隐式通信，同时需要指定方法或者变量之间的锁的关系来使得线程完成数据操作，这样做到了显示同步。 消息传递 消息传递是通过两个线程之间的消息队列，也就是线程A对线程B直接发起的消息通信，来完成信息传递。在这个过程中，线程之间没有公共状态，必须通过发送消息来显式进行通信，同时因为发送消息总是能够在接收消息之前，做到了隐式同步。 并发模型 通信机制 同步机制 共享内存 线程之间共享公共状态，通过写-读内存中的公共状态进行隐式通信。 必须指定线程的互斥执行顺序，做到显式同步。 消息传递 线程没有公共状态，所以必须通过发送消息来进行显式通信。 消息的发送必须在消息的接收之前，所以进行隐式的同步。 volatile的作用及实现​ volatile能够对一个变量的读-写操作进行同步，对于单个变量的读-写操作，能够看成是使用同一个锁对读-写操作进行了同步。 volatile特性： 可见性：对一个volatile变量的读，总是能够看到（任意线程）对这个volatile变量最后的写入。原子性：对单个volatile变量的读/写操作具有原子性，但是对于复合操作不具有原子性，哪怕这个复合操作是基于volatile变量。 ​ volatile通过JSR-133定义的happens-before关系，来实现在两个线程之间的通信。 happens-before关系 如果一个操作执行的结果对另一个操作可见，那么这两个操作之间必须存在happens-before关系。这两个操作可以是在同一个线程之内，也可以在多个线程之间。 happens-before规则 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。监视器锁规则：对一个锁的解锁，happens-before于随后对于这个锁的加锁。volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。 as-if-serial 语义 as-if-serial语义是指：不管怎么重排序，（单线程）的执行结果不能被改变。 ​ 在写入一个共享volatile变量时，JMM会把该新城对应的本地内存中的共享变量值刷新到主内存；在读一个volatile变量时，JMM会把该线程对应的本地内存设置为无效，线程会从主内存中读取共享变量。通过对volatile变量写之后的写入主内存操作和读之前的从主内存读取操作，保证了可见性。 volatile通过在JMM（Java Momery Modal）层次插入内存屏障，来做到对指令重排序的禁止。 在JMM中，volatile对于内存屏障的实现是悲观的： 每次写操作前插入StoreStore屏障，写操作后插入StoreLoad屏障每次读操作前插入LoadLoad屏障，读操作后插入LoadStore屏障 ​ 满足下列条件，volatile可以使用： 对变量的写入不依赖变量的当前值变量不包含在具有其他变量的不变式中 volatile为什么不能保证原子性​ 尽管volatile在内存可见性方面表现出了锁的状态，但是volatile并不是锁，所以不能够提供原子性。 在上面的这个程序中，如果在单线程中执行，那么这个操作将不会有错误，但是当放到并发环境中进行执行的时候，哪怕变量count是volatile变量，在写入之后能够将数据刷回主内存，但是这个程序依然是存在危险的。问题的原理同共享内存模型中不能够保持原子性的原理，即++操作属于复合操作，并非原子操作。 volatile跟synchronized的差别​ synchronized实现可见性的时候，在线程角度执行互斥代码需要做到： 获得互斥锁清空工作内存拷贝变量的最新副本到工作内存执行代码将更改后的变量的值刷新到主内存释放锁 ​ volatile不是锁，但是volatile提供了原子变量在内存中的可见性，在并发设计中，这个操作将能够大大节省系统的开销。对于volatile的读，相当于synchronized的加锁，volatile的写，相当于synchronized的解锁，但是volatile不会阻塞线程，响应速度更快。 volatile本质上是工作内存中的值不确定的，需要从主内存中重新读取；而synchronized本质是使用锁将变量锁定，只有当前变量可以访问，其他变量将被阻塞。volatile只是存在于变量级别，而synchronized存在于变量，方法和类级别。volatile只能怪保证内存可见性，不能保证原子性操作；而synchronized可以保证原子性和可见性。 关于volatile还需要知道什么​ volatile对于64位的Long类型变量有着优化。 这一点需要从处理器总线的工作机制说起，在一些32位的处理器上，JVM运行时可能会把一个64位long/double类型的变量的写操作拆分为两个32位的写操作，并且将这两个32位的写操作分配到不同的总线事务中执行，此时这个64位变量的写操作不再具有原子性。同样的，读64位操作也是有可能是非原子的。通过将一个long/double变量声明为volatile的，JMM保证这些变量的set和get操作是原子的。","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"},{"name":"同步语义","slug":"同步语义","permalink":"http://yoursite.com/tags/同步语义/"}]},{"title":"内存屏障","slug":"内存屏障","date":"2018-04-11T07:19:25.000Z","updated":"2018-07-15T07:31:44.786Z","comments":true,"path":"2018/04/11/内存屏障/","link":"","permalink":"http://yoursite.com/2018/04/11/内存屏障/","excerpt":"","text":"内存屏障内存屏障是个啥？​ 内存屏障，是计算机CPU在多核时代，通过数据拷贝，将一个处理器的内存状态对其他处理器可见。在百度百科中，内存屏障也被称呼为内存栅栏，内存栅障，屏障指令等。乍一看到内存栅栏这个这个名词，我还以为这个是跟Java栅栏是一个东西，但是实际上两者并不相同。 在执行CPU指令的时候，CPU会对指令进行乱序执行，来优化性能（这一点我在《共享内存模型》一文中有提到过）。而在多线程的时候，乱序执行可能会导致代码的执行跟预期结果不同，内存屏障同时阻止指令排序行为的发生。 内存屏障有啥用？​ 在CPU层次，内存屏障分为两种：读屏障 Load Barrier 和写屏障 Store Barrier。读屏障表示在线程读取前，将主存的内容载入到缓存或者是线程内存里。写屏障表示在缓存或者线程内存里插入后，将更新写入到主内存里。 通过内存屏障，主内存和缓存（线程内存）之间做到了数据统一，保证了可见性。也就是说通过内存屏障，已经达成了共享内存模型的可见性要求。 内存屏障的缺陷​ 通过内存屏障，保证了数据可见性，同时防止屏障两端指令的重排序。但是内存屏障做不到并发过程中的原子性，这个也就是volatile关键字仅仅能够提供可见性，却不能够提供原子性的原因，因为volatile的实现就是通过内存屏障来进行实现的。 内存屏障做不到原子性的原因:当存在两个线程Ta和Tb以及一个共享变量count=0，第一时刻Ta读取了count的值，这个读操作采用了内存屏障，读取前将Ta线程的内存里的数据清空，然后将主存的count复制到Ta线程的内存。Ta线程执行count的++操作，此时Tb线程读取count的值，此时主存内count的值为0。Ta执行变量count的++操作结束，将数据写回。同时Tb将读取的count执行++操作。此时主存内count的值为1。Tb将数据写回。此时主存内的count值仍为1。 ​ 如果程序的执行是正确的，那么最终结果应该是count=2，但是因为在程序执行过程中不提供原子性支持，所以会出现错误。 这一部分内容都是CPU层次的内存屏障，下面的内容是Java层次的内存屏障。 Java内存屏障​ Java内存屏障包括四种：LoadStore，StoreStore，LoadLoad，StoreLoad。也就是CPU层次的内存屏障两两结合。 LoadLoad ： 对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。StoreStore ： 对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。LoadStore ： 对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。StoreLoad ： 对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能，但是开销相对较大。 JVM层次对于内存屏障的实现volatile语义中的内存屏障​ volatile对于内存屏障实现是悲观的，对于volatile变量： 每次写操作前插入StoreStore屏障，写操作后插入StoreLoad屏障每次读操作前插入LoadLoad屏障，读操作后插入LoadStore屏障 ​ 同样的，因为内存屏障的缺陷，volatile不能够表现出原子性的特性，仅仅能够提供内存可见性。 final语义中的内存屏障​ 在final域里，分别针对屏障做出了规则限制： 写final域 JMM禁止编译器把final域的写重排序到构造函数外。编译器会在final域的写之后，return之前，插入StoreStore屏障。 读final域 初次读对象引用域初次读该对象包含的final域，JMM禁止处理器重排序这两个操作。 ​ 也就是说，对于final域，总是在一个对象的所有final域写入完毕后才能读取和引用。","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"},{"name":"内存屏障","slug":"内存屏障","permalink":"http://yoursite.com/tags/内存屏障/"}]},{"title":"共享内存模型","slug":"共享内存模型","date":"2018-04-09T07:19:16.000Z","updated":"2018-07-15T07:30:50.486Z","comments":true,"path":"2018/04/09/共享内存模型/","link":"","permalink":"http://yoursite.com/2018/04/09/共享内存模型/","excerpt":"","text":"共享内存模型共享内存模型​ 在线程与锁之间，一个非常简单的并发模型是–共享内存模型。共享内存模型是指通过共享内存来实现并发的模型。 共享内存模型中，当多个线程在并发执行过程中对共享资源进行处理时候，如果没有进行一定的同步处理，那么就会出现读脏、数据无效的问题。在共享内存模型中，非常重要的两个概念是：内存可见性+原子性。 Java中多个线程之间的通信就是通过共享变量来进行的，JVM里面主内存是所有内存共享的，而每个线程拥有自己的工作内存，线程只能在自己的工作内存中处理数据。那么很明显的，在内存之间对共享变量处理过程就容易出现错误问题。 内存可见性​ 内存可见性保证了Java多线程并发处理过程中，不同的线程对于共享资源的处理，能够保证始终被其他线程观察到。例如对某一个共享数据的处理，其他线程始终能够看到这个共享数据的最新值，无论这个数据是在哪一个线程中进行修改的。 12345678910111213141516171819202122232425262728public class Counting &#123; public static void main(String[] args) throws InterruptedException&#123; class Counter &#123; private int count = 0; public void increment() &#123; ++count; &#125; public int getCount() &#123; return count; &#125; &#125; final Counter counter = new Counter(); class CountingThread extends Thread &#123; @Override public void run() &#123; for (int x=0;x&lt;10000;x++) &#123; counter.increment(); &#125; &#125; &#125; CountingThread t1 = new CountingThread(); CountingThread t2 = new CountingThread(); t1.start();t2.start(); t1.join();t2.join(); System.out.println(counter.getCount()); &#125;buding&#125;//程序来源：《Seven Concurrency Models in Seven Weeks》 ​ 在上述代码中，有两个线程，分别对一个共享变量count进行+10000操作，如果程序是正常的，那么输出的值应该是20000，然而因为线程每次进行+1操作之后，修改的值对另一个线程不可见，而对数据进行更新到主内存的时间不定，所以多次测试结果都不相同。同样的，这个程序也违反了变量模型的原子性。 原子性​ 并发的原子性表现为在多线程操作中，对于某一个共享变量的操作，每个线程的操作都应该是原子性的。例如在Java中，对于一个数据的自增，也就是X++，这个操作实际上是读-改-写模式的操作，当在多线程中操作的时候，可能会存在线程a进行读取。线程b进行读取，同时两个线程分别对其进行++操作，但是最终的结果可能是1，也就是++操作不是原子操作。 维持原子操作的方法，在共享内存模型中，是对共享内存进行加锁操作。通过加锁操作，持有一个共享对象的锁，将一个线程对该对象的操作转换为原子操作，保证程序的原子性。 非常诡异的现象​ 在Java中，存在着一些非常有意思的操作：指令重排序（乱序执行）。当出现指令重排序的时候，Java会打乱代码的执行顺序，也就是说，对于代码的执行会处于不可控状态，这个状态跟线程的乱序执行是一样的道理。 1234导致在执行过程中发生乱序执行的原因有这么几种情况： 编译器的静态优化可以打乱代码的执行顺序。 JVM的动态优化会打乱代码的执行顺序。 硬件可以通过乱序执行来优化其性能。 ​ 乱序执行造成的影响： 12345678910111213141516171819202122232425public class Puzzle &#123; static boolean answerReady = false; static int answer = 0; static Thread t1 = new Thread()&#123; @Override public void run() &#123; answer = 42; answerReady = true; &#125; &#125;; static Thread t2 = new Thread()&#123; @Override public void run() &#123; if (answerReady) System.out.println(&quot;The meaning of life is: &quot; + answer + &quot;.&quot;); else System.out.println(&quot;I don&apos;t know the answer.&quot;); &#125; &#125;; public static void main(String[] args) throws InterruptedException&#123; t1.start();t2.start(); t1.join();t2.join(); &#125;&#125;//程序来源：《Seven Concurrency Models in Seven Weeks》 ​ 上述代码中，正确的执行输出结果应该是：The meaning of life is: 42.但是当乱序执行的时候，可能会出现一种结果：The meaning of life is: 0.解决方案是Java中有些机制可以使程序在编译器、处理器优化时会对有数据依赖的禁止指令重排序，如：volatile、synchronized等。 共享内存模型主要要满足两点需求：内存可见性和原子性，满足这个条件的线程是安全的。","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"},{"name":"内存模型","slug":"内存模型","permalink":"http://yoursite.com/tags/内存模型/"}]},{"title":"检测String的不可变性及String赋值的实质","slug":"检测String的不可变性及String赋值的实质","date":"2018-03-18T07:18:58.000Z","updated":"2018-07-15T07:30:06.910Z","comments":true,"path":"2018/03/18/检测String的不可变性及String赋值的实质/","link":"","permalink":"http://yoursite.com/2018/03/18/检测String的不可变性及String赋值的实质/","excerpt":"","text":"检测String的不可变性及String赋值的实质String实现​ 从学习Java不久，就有人跟我讲过String是不可变的，也就是新建出来的String对象就不能够进行改变，对其进行改变会新建一个String对象，并且对其进行赋值。阅读了一下String的源码实现，简单的了解了一下机制。 首先String类是被定义为了final的，然后内部实现的数组也定义为了final，对于这个final的使用，我大概只是了解到在这里是防止String被继承，并且保证String的不可变性的。但是，还是理解不透彻，我就去百度搜了搜，在知乎看到了一个非常有意思的回答，然后自己实现了一下。 123456public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; @Stable private final byte[] value; private final byte coder; private int hash; // Default to 0 ​ 首先String的底层是通过一个byte数组来进行实现的，在百度的时候，我查到很多博客或者文章里面给出的String实现都是char数组，是JDK在版本更新改了底层实现。 在我看到的知乎回答里面，对String的不变性有一个非常棒的解释。从实现的数组讲，final Array是不能够对数组里面的数据进行final的，也就是final数组无法阻止数据更变。 String的防止改变的实现是将底层数据私有化，并且没有将内部数据开放，所以才可以实现了String 的不可变性。 String的赋值检测 String的赋值实际上只是对引用的赋值，我写了段代码进行验证。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"源码解读","slug":"源码解读","permalink":"http://yoursite.com/tags/源码解读/"}]},{"title":"Vector自动增加数组容量的实现","slug":"Vector自动增加数组容量的实现","date":"2018-03-13T07:18:42.000Z","updated":"2018-07-15T07:28:19.554Z","comments":true,"path":"2018/03/13/Vector自动增加数组容量的实现/","link":"","permalink":"http://yoursite.com/2018/03/13/Vector自动增加数组容量的实现/","excerpt":"Vector自动增加数组容量的实现​ 昨天在了解到ArrayList的自动扩容之后，忽然想到在Java的另外一个类-Vector里面，实现了数组的自动增长，然后看源码了解了一下。","text":"Vector自动增加数组容量的实现​ 昨天在了解到ArrayList的自动扩容之后，忽然想到在Java的另外一个类-Vector里面，实现了数组的自动增长，然后看源码了解了一下。 1234567891011121314151617181920212223242526272829 /** * The array buffer into which the components of the vector are * stored. The capacity of the vector is the length of this array buffer, * and is at least large enough to contain all the vector&apos;s elements. * * &lt;p&gt;Any array elements following the last element in the Vector are null. * * @serial */ protected Object[] elementData; /** * The number of valid components in this &#123;@code Vector&#125; object. * Components &#123;@code elementData[0]&#125; through * &#123;@code elementData[elementCount-1]&#125; are the actual items. * * @serial */ protected int elementCount;有趣的java.util.*List /** * The amount by which the capacity of the vector is automatically * incremented when its size becomes greater than its capacity. If * the capacity increment is less than or equal to zero, the capacity * of the vector is doubled each time it needs to grow. * * @serial */ protected int capacityIncrement; ​ 在Vector内部，通过定义两个int变量来控制一个Vector数组的增长。elementCount指的是当前数组的使用量，capacityIncrement指的是在数组需要增加容量的时候增加的大小，elementData是一个底层的数组。 123456789101112131415161718192021222324252627282930313233343536373839private Object[] grow(int minCapacity) &#123; return elementData = Arrays.copyOf(elementData, newCapacity(minCapacity)); &#125; private Object[] grow() &#123; return grow(elementCount + 1); &#125; /** * Returns a capacity at least as large as the given minimum capacity. * Will not return a capacity greater than MAX_ARRAY_SIZE unless * the given minimum capacity is greater than MAX_ARRAY_SIZE. * * @param minCapacity the desired minimum capacity * @throws OutOfMemoryError if minCapacity is less than zero */ private int newCapacity(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt;= 0) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return minCapacity; &#125; return (newCapacity - MAX_ARRAY_SIZE &lt;= 0) ? newCapacity : hugeCapacity(minCapacity); &#125; private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; ​ 跟ArrayList没有什么区别，Vector也是好几个方法套来套去实现数组的扩容，套来套去是为了保证代码的实用性和安全性。但是跟ArrayList实现方法不一样的是，在Vector内部，通过capacityIncrement来对数组的扩增进行长度控制，当数组需要扩容时，检查capacityIncrement的值，如果不非零，那么每次扩容都增加capacityIncrement的长度，如果非零，那么每次增加的量是原数组的长度，也就是oldCapacity。capacityIncrement的值是通过在建立一个Vector的时候在构造器中传入的： 12345678910111213141516171819/** * Constructs an empty vector with the specified initial capacity and * capacity increment. * * @param initialCapacity the initial capacity of the vector * @param capacityIncrement the amount by which the capacity is * increased when the vector overflows * @throws IllegalArgumentException if the specified initial capacity * is negative */ public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement; &#125; ​ 这样子的实现使得Vector成为了可控的自增数组。 ArrayList实现：有趣的java.util.*List 奇妙的设计思想​ 这段话是我在读完Stack的源码之后加上的。至于为什么加到这里，因为我是真的对JDK的设计思路感到神奇。 Stack，这个栈，我印象中在我学习数据结构的时候，自己创建一个栈，使用了各种绕来绕去的方法，写上两三百行的代码(当然，这个并不包括注释，就算包括，也不会再多太多)，这之间可能自己都绕不过来，然后才实现了一个勉强能够使用的Stack类。但是当我看到源码中的Stack，继承了Vector数组，这也是我把这段话写到这里的原因，然后Vector定义了一些极具通用性的方法，然后直接调用，付出的只是些参数，例如Stack的长度，然后就把一个Stack类写完了。哇，神奇的设计思路。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"源码解读","slug":"源码解读","permalink":"http://yoursite.com/tags/源码解读/"}]},{"title":"双轴快排了解一下","slug":"双轴快排了解一下","date":"2018-03-12T07:18:22.000Z","updated":"2018-07-15T07:25:40.194Z","comments":true,"path":"2018/03/12/双轴快排了解一下/","link":"","permalink":"http://yoursite.com/2018/03/12/双轴快排了解一下/","excerpt":"双轴快排了解一下​ 在JDK1.7之前，Java在Arrays类包里使用的排序算法是快速排序，在JDK1.7之后，Arrays仍然使用快速排序，不过是从一般的快排转到了双轴快排。","text":"双轴快排了解一下​ 在JDK1.7之前，Java在Arrays类包里使用的排序算法是快速排序，在JDK1.7之后，Arrays仍然使用快速排序，不过是从一般的快排转到了双轴快排。 快速排序​ 快速排序是一个非常高效的排序算法，在最有时间时的O(nlogn),在最坏的情况下才是O(n * n)。但是可以通过优化选择轴线的大小，来尽可能的提高算法的效率。 在快速排序算法中，需要选择一个轴线，然后对需要排序的数组从前从后分别遍历，选择出大于轴线的值的数字放到轴线右侧，小于轴线的数字放到轴线左侧，当这一次的数组排序结束之后，进行递归的方法，分别对轴线左侧和右侧的数组进行快排的递归，直到整个数组进行排序结束。 影响快排的一个重要因素是轴线的选择，而在普通快排中，使用三数中值分割法来进行轴线的选择，提高算法效率。 双轴快排​ 从JDK1.7起，Java在排序算法中的实现就转换成了双轴快排。 双轴快排，顾名思义，在排序的过程中采用两条轴线进行排序。选取轴线之后，先对轴线进行排序，比较出大小顺序。然后在比较过程中，将小于最小轴线的数字放到左轴线左侧，将大于最大轴线的数字放到右轴线右侧，剩余的放到两条轴线中间。同样的在划分好的三个区域内使用递归的双轴快排来对数组进行排序。 JDK中的实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879static void sort(int[] a, int left, int right, int[] work, int workBase, int workLen) &#123; if (right - left &lt; QUICKSORT_THRESHOLD) &#123; sort(a, left, right, true); return; &#125; int[] run = new int[MAX_RUN_COUNT + 1]; int count = 0; run[0] = left; for (int k = left; k &lt; right; run[count] = k) &#123; while (k &lt; right &amp;&amp; a[k] == a[k + 1]) k++; if (k == right) break; if (a[k] &lt; a[k + 1]) &#123; while (++k &lt;= right &amp;&amp; a[k - 1] &lt;= a[k]); &#125; else if (a[k] &gt; a[k + 1]) &#123; // descending while (++k &lt;= right &amp;&amp; a[k - 1] &gt;= a[k]); for (int lo = run[count] - 1, hi = k; ++lo &lt; --hi; ) &#123; int t = a[lo]; a[lo] = a[hi]; a[hi] = t; &#125; &#125; if (run[count] &gt; left &amp;&amp; a[run[count]] &gt;= a[run[count] - 1]) &#123; count--; &#125; if (++count == MAX_RUN_COUNT) &#123; sort(a, left, right, true); return; &#125; &#125; if (count == 0) &#123; return; &#125; else if (count == 1 &amp;&amp; run[count] &gt; right) &#123; return; &#125; right++; if (run[count] &lt; right) &#123; run[++count] = right; &#125; byte odd = 0; for (int n = 1; (n &lt;&lt;= 1) &lt; count; odd ^= 1); int[] b; int ao, bo; int blen = right - left; if (work == null || workLen &lt; blen || workBase + blen &gt; work.length) &#123; work = new int[blen]; workBase = 0; &#125; if (odd == 0) &#123; System.arraycopy(a, left, work, workBase, blen); b = a; bo = 0; a = work; ao = workBase - left; &#125; else &#123; b = work; ao = 0; bo = workBase - left; &#125; for (int last; count &gt; 1; count = last) &#123; for (int k = (last = 0) + 2; k &lt;= count; k += 2) &#123; int hi = run[k], mi = run[k - 1]; for (int i = run[k - 2], p = i, q = mi; i &lt; hi; ++i) &#123; if (q &gt;= hi || p &lt; mi &amp;&amp; a[p + ao] &lt;= a[q + ao]) &#123; b[i + bo] = a[p++ + ao]; &#125; else &#123; b[i + bo] = a[q++ + ao]; &#125; &#125; run[++last] = hi; &#125; if ((count &amp; 1) != 0) &#123; for (int i = right, lo = run[count - 1]; --i &gt;= lo; b[i + bo] = a[i + ao] ); run[++last] = right; &#125; int[] t = a; a = b; b = t; int o = ao; ao = bo; bo = o; &#125; &#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"双轴快排","slug":"双轴快排","permalink":"http://yoursite.com/tags/双轴快排/"},{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"有趣的java.util.*List","slug":"有趣的java.util.List","date":"2018-03-12T07:17:48.000Z","updated":"2018-07-15T07:23:31.666Z","comments":true,"path":"2018/03/12/有趣的java.util.List/","link":"","permalink":"http://yoursite.com/2018/03/12/有趣的java.util.List/","excerpt":"","text":"有趣的java.util.*List​ 阅读容器的源码，然后读到了一些有意思的东西。 LinkedList&amp;ArrayList的底层关系​ 先从两个链表的底层实现看，LinkedList是通过继承AbstractSequentialList这个抽象类，实现List、Deque、接口实现的，而ArrayList是直接通过List实现的，所以，从底层实现看，LinkedList实现要更加复杂。 底层的实现​ 在ArrayList类的内部，ArrayList构建了一个默认数组，对于有参构造器数组的长度默认为10，对于无参构造器ArrayList构造了一个默认的空的数组来进行实现。 在Linkedlist类的内部，Linkedlist通过构建了一个双链表来进行实现。 ArrayList的扩容​ ArrayList通过一个数组来进行实现，那么数组的优点是能够快速的进行数据检索，但是插入和删除相较Linkedlist更加困难，除此之外，数组的特性也决定了扩容一个数组是非常困难的，然后阅读了一下源码内对于扩容的实现方法。 123456789101112131415161718192021222324252627282930313233343536373839404142public void ensureCapacity(int minCapacity) &#123; if (minCapacity &gt; elementData.length &amp;&amp; !(elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA &amp;&amp; minCapacity &lt;= DEFAULT_CAPACITY)) &#123; modCount++; grow(minCapacity); &#125; &#125; private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; private Object[] grow(int minCapacity) &#123; return elementData = Arrays.copyOf(elementData, newCapacity(minCapacity)); &#125; private Object[] grow() &#123; return grow(size + 1); &#125; private int newCapacity(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt;= 0) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) return Math.max(DEFAULT_CAPACITY, minCapacity); if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return minCapacity; &#125; return (newCapacity - MAX_ARRAY_SIZE &lt;= 0) ? newCapacity : hugeCapacity(minCapacity); &#125; private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; ​ 能够看到，ArrayList建立一个新的数组，这个数组的容量通过移位运算扩展为现在数组的1.5倍，然后将原数组复制到新数组之中，在将引用转向原数组来实现扩容。 12345678910111213public void add(int index, E element) &#123; rangeCheckForAdd(index); modCount++; final int s; Object[] elementData; if ((s = size) == (elementData = this.elementData).length) elementData = grow(); System.arraycopy(elementData, index, elementData, index + 1, s - index); elementData[index] = element; size = s + 1;&#125; ​ 在实际使用过程中，即添加一个新项，但是新项超出数组上限，然后调用方法进行数组扩容。 LinkedList的实现-双链表1234567891011121314151617181920Linkedlist实现： transient int size = 0; transient Node&lt;E&gt; first; transient Node&lt;E&gt; last; private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; ​ 通过阅读源码，能够看到JDK对于LInkedlist的实现是采用了一个双链表，那么问题来了，为什么不采用单链表？我没有能够查找到相关信息，但是通过阅读源码，我发现Linkedlist在查找某一个结点的过程中是通过一种类似于折半查找的方法来进行查找，为什么说类似，是因为这种二分查找只进行一次，也就是在得到结点的位置的时候，通过比较位置的大小和链表的长度，来确定查找的范围。所以，能够推测，在整个链表的查找中，运用这种类似的前后方向不同的查找，所以，Linkedlist采用了双链表作为实现方法。 1234567891011121314Linkedlist查找结点的方法： Node&lt;E&gt; node(int index) &#123; if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"源码解读","slug":"源码解读","permalink":"http://yoursite.com/tags/源码解读/"}]},{"title":"有趣的java.util.*List","slug":"有趣的java-util-List","date":"2018-03-12T07:17:48.000Z","updated":"2018-07-15T07:25:52.274Z","comments":true,"path":"2018/03/12/有趣的java-util-List/","link":"","permalink":"http://yoursite.com/2018/03/12/有趣的java-util-List/","excerpt":"有趣的java.util.*List​ 阅读容器的源码，然后读到了一些有意思的东西。","text":"有趣的java.util.*List​ 阅读容器的源码，然后读到了一些有意思的东西。 LinkedList&amp;ArrayList的底层关系​ 先从两个链表的底层实现看，LinkedList是通过继承AbstractSequentialList这个抽象类，实现List、Deque、接口实现的，而ArrayList是直接通过List实现的，所以，从底层实现看，LinkedList实现要更加复杂。 底层的实现​ 在ArrayList类的内部，ArrayList构建了一个默认数组，对于有参构造器数组的长度默认为10，对于无参构造器ArrayList构造了一个默认的空的数组来进行实现。 在Linkedlist类的内部，Linkedlist通过构建了一个双链表来进行实现。 ArrayList的扩容​ ArrayList通过一个数组来进行实现，那么数组的优点是能够快速的进行数据检索，但是插入和删除相较Linkedlist更加困难，除此之外，数组的特性也决定了扩容一个数组是非常困难的，然后阅读了一下源码内对于扩容的实现方法。 123456789101112131415161718192021222324252627282930313233343536373839404142public void ensureCapacity(int minCapacity) &#123; if (minCapacity &gt; elementData.length &amp;&amp; !(elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA &amp;&amp; minCapacity &lt;= DEFAULT_CAPACITY)) &#123; modCount++; grow(minCapacity); &#125; &#125; private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; private Object[] grow(int minCapacity) &#123; return elementData = Arrays.copyOf(elementData, newCapacity(minCapacity)); &#125; private Object[] grow() &#123; return grow(size + 1); &#125; private int newCapacity(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt;= 0) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) return Math.max(DEFAULT_CAPACITY, minCapacity); if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return minCapacity; &#125; return (newCapacity - MAX_ARRAY_SIZE &lt;= 0) ? newCapacity : hugeCapacity(minCapacity); &#125; private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; ​ 能够看到，ArrayList建立一个新的数组，这个数组的容量通过移位运算扩展为现在数组的1.5倍，然后将原数组复制到新数组之中，在将引用转向原数组来实现扩容。 12345678910111213public void add(int index, E element) &#123; rangeCheckForAdd(index); modCount++; final int s; Object[] elementData; if ((s = size) == (elementData = this.elementData).length) elementData = grow(); System.arraycopy(elementData, index, elementData, index + 1, s - index); elementData[index] = element; size = s + 1;&#125; ​ 在实际使用过程中，即添加一个新项，但是新项超出数组上限，然后调用方法进行数组扩容。 LinkedList的实现-双链表1234567891011121314151617181920Linkedlist实现： transient int size = 0; transient Node&lt;E&gt; first; transient Node&lt;E&gt; last; private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; ​ 通过阅读源码，能够看到JDK对于LInkedlist的实现是采用了一个双链表，那么问题来了，为什么不采用单链表？我没有能够查找到相关信息，但是通过阅读源码，我发现Linkedlist在查找某一个结点的过程中是通过一种类似于折半查找的方法来进行查找，为什么说类似，是因为这种二分查找只进行一次，也就是在得到结点的位置的时候，通过比较位置的大小和链表的长度，来确定查找的范围。所以，能够推测，在整个链表的查找中，运用这种类似的前后方向不同的查找，所以，Linkedlist采用了双链表作为实现方法。 1234567891011121314Linkedlist查找结点的方法： Node&lt;E&gt; node(int index) &#123; if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"源码解读","slug":"源码解读","permalink":"http://yoursite.com/tags/源码解读/"}]},{"title":"接口和抽象类","slug":"接口和抽象类","date":"2018-03-11T06:37:13.000Z","updated":"2018-07-15T07:26:16.070Z","comments":true,"path":"2018/03/11/接口和抽象类/","link":"","permalink":"http://yoursite.com/2018/03/11/接口和抽象类/","excerpt":"接口和抽象类​ 本没有计划整理这个抽象类或者接口的知识点的，因为这两个概念非常的简单了，无非是对类的抽象和高度抽象。但是在读过Java9的源码之后，因为增加了default关键字，所以，整理一下这个知识点。","text":"接口和抽象类​ 本没有计划整理这个抽象类或者接口的知识点的，因为这两个概念非常的简单了，无非是对类的抽象和高度抽象。但是在读过Java9的源码之后，因为增加了default关键字，所以，整理一下这个知识点。 接口​ 在类里，使用继承来描述一个类遵循接口的定义并不太合适，因为调用该接口的类与这个接口并没有实际的包含关系，即is-a的关系，所以，使用一个类实现了某个接口更为合适。 ​ 使用abstract显式定义抽象类，使用interface定义接口。interface定义的接口是更加抽象的抽象类。接口中的方法可以通过default关键字定义为可包含方法实体的方法，否则只能够包含方法声明。接口中的方法隐式的声明为public，尽量将其显式声明。接口内的成员变量都被隐式声明为public,static,final，并且需要显式初始化，成员变量为常量（大写，使用_间隔词语）。 ​ 让一个类遵循某个接口：使用inplements关键字，将接口的方法重新在类中声明定义。允许同一个接口具有多个不同的具体实现，常用策略设计模式。可以在任何类上添加新的接口，让方法接受接口类型，这是一种让任何类都可以对该方法进行适配的方式。 ​ 接口不具备任何形式的类型，所以来自多个类型的类都是可以继承同一个接口的。 ​ 接口可以多重继承。 ​ 在导出类中，不强制要求必须有一个是抽象的或“具体的“（没有任何抽象方法的）基类。如果要从一个非接口的类继承，那么只能从一个类继承。其余的基元素必须是接口。需要将所有的接口名都置于inplements关键字之后，用逗号一一隔开。可以继承任意多个接口，并可以向上转型为每个接口，因为每个接口都是一个独立类型。换而言之，一个类可以继承多个接口，只要书写符合规范。接口也可以继承，通过继承接口产生新的接口。使用extends继承接口，并且可以继承多个接口，只要书写符合规范，即将接口名用逗号分隔。 ​ 接口可以嵌套在类或其他接口中。实现某个接口时，不需要实现嵌套在其内部的任何接口，private接口不能在定义它的类之外实现。 ​ 在打算组合的不同接口中使用相同的方法名会造成代码的可读性的混乱。 抽象类​ 抽象类（抽象基类）：含有抽象方法的类，当一个类含有一个或多个抽象方法，该类必须被限定为抽象(abstract)的。建立一个基类，这个基类仅提供接口，即创建类的通用部分，表示所有导出类的共同部分。这个类的对象没有实际意义，因为类只是表示一个接口，没有具体的实现内容，不同的子类可以用不同的方式表示这些接口。 ​ 继承时候，抽象类的抽象方法需要在导出类全部重写，否则导出类也是抽象类，直到所有的抽象方法全部被重写。 ​ 抽象类内是可以不含有抽象方法的，也就是可以含有可实现的方法，但是不能实例化。 ​ 抽象方法：方法使用abstract声明，抽象方法是不完整的，仅有方法声明，没有方法体。 ​ 抽象类的继承同一般类的继承，使用extends。这点不同于接口。 辨析相同点 12* 都不能被直接实例化，都可以通过继承实现其抽象方法。* 都是面向抽象编程的技术基础，实现了诸多的设计模式。 不同点 12345678* 接口支持多继承；抽象类不能实现多继承。* 接口只能定义抽象规则；抽象类既可以定义规则，还可能提供已实现的成员。* 接口是一组行为规范；抽象类是一个不完全的类，着重族的概念。* 接口可以用于支持回调;抽象类不能实现回调，因为继承不支持。* 接口只包含方法、属性、索引器、事件的签名，但不能定义字段和包含实现的方法(非default定义)；抽象类可以定义字段、属性、包含有实现的方法。 * 接口可以作用于值类型和引用类型；抽象类只能作用于引用类型。例如，Struct就可以继承接口，而不能继承类* 接口定义不同类型之间的类的方法;抽象类只定义了子类可以使用的方法。* 接口中的方法都具有public的访问权限;抽象类里的方法可以具有正常类的访问权限。 查看更多Java基础：Java基础","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"基础","slug":"基础","permalink":"http://yoursite.com/tags/基础/"}]},{"title":"Java的全新关键字-default","slug":"Java的全新关键字-default","date":"2018-03-11T06:36:59.000Z","updated":"2018-07-15T07:26:40.562Z","comments":true,"path":"2018/03/11/Java的全新关键字-default/","link":"","permalink":"http://yoursite.com/2018/03/11/Java的全新关键字-default/","excerpt":"Java的全新关键字-default​ 有在读Jdk9的持有对象源代码，然后读到了Iterator.java文件，接口中定义了四个方法： 1234boolean hasNext()E next()default void remove()&#123;&#125;default void forEachRemaining()&#123;&#125; ​ 在接口的方法定义中发现了一个关键字：default，并不能理解这个关键字，然后去百度查了一下定义。","text":"Java的全新关键字-default​ 有在读Jdk9的持有对象源代码，然后读到了Iterator.java文件，接口中定义了四个方法： 1234boolean hasNext()E next()default void remove()&#123;&#125;default void forEachRemaining()&#123;&#125; ​ 在接口的方法定义中发现了一个关键字：default，并不能理解这个关键字，然后去百度查了一下定义。 接口允许确定方法名、参数列表和返回类型，但是没有任何方法体。接口只提供了形式，而未提供任何具体实现(Think in java)，在《Think in Java》一书的描述中，JavaSE5中对接口的限定是非常明确的。在java8中，引入了新的概念default方法，也可以成为Defender方法，或者虚拟扩展方法。 Default方法是指，在接口内部包含了一些默认的方法实现（也就是接口中可以包含方法体，这打破了Java之前版本对接口的语法限制），从而使得接口在进行扩展的时候，不会破坏与接口相关的实现类代码。(Default methods enable you to add new functionality to the interfaces of your libraries and ensure binary compatibility with code written for older versions of those interfaces.) 诚然，这个关键字真正的给后期维护在扩展接口时候提供了非常强的帮助。但是，Java坚持了这么多年的通过接口来防止多重继承容易造成二义性这一回事，因为这个关键字，转了一圈又回来了。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"Java新特性","slug":"Java新特性","permalink":"http://yoursite.com/tags/Java新特性/"}]},{"title":"Java多态","slug":"Java多态","date":"2018-03-09T06:36:36.000Z","updated":"2018-07-15T07:14:45.144Z","comments":true,"path":"2018/03/09/Java多态/","link":"","permalink":"http://yoursite.com/2018/03/09/Java多态/","excerpt":"","text":"Java多态原文 ​ java 多态，个人理解为一个类的接口，多种不同的实现方式。 通过这一个类（基类），对其进行继承，然后基类里面的某一个方法（或指接口），在子类内部进行重写，然后在进行调用，实际实现者为子类，但是调用这个方法的为基类的方法。这是多态的一种实现方式。 ​ 多态：一个接口，多个实现。 个人理解：我们目前有一些网红，这些网红都是伴随着信息社会的产物，从宏观意义上讲，我们这些网红都是一样的，这就是一个接口，但是从微观意义上讲，每一个网红都不一样，网红之间存在着非常大的差异，当我们调用网红的时候，我们会得到很多种的不同的网红，这就是多个实现。 ​ Java 中存在的机制，让我们对于想要调用的某个实现，我们只需要使用这个接口，Java会自行根据当前接口对应的实例，去实现这一个过程或者目的。 ​ 对于调用构造器内部的一个动态绑定方法，用到的是方法被覆盖后的定义。Java都是通过动态绑定实现多态。一个静态方法不具有多态性，只有普通方法调用是可以多态的。 补充​ 对于多态，Java中非常重要的一个处理是对于大多数方法使用了运行时绑定（后期绑定、动态绑定），所以在运行时能够根据方法调用绑定类型信息，进行向上转型。存在特殊的方法类型是static方法和final方法，Private方法默认为final方法。 对域进行的绑定是编译器解析，也不能够进行动态绑定。 构造器的多态​ 在构造器内部如果有使用多态的方法的话，会造成导出类使用覆盖方法的定义。所以尽可能简单的让对象进入正常状态，避免调用其他方法，在构造器内唯一能够安全调用的方法是基类的final方法。 Java的转型​ 在多态中，Java进行了向上转型：在继承结构上向上移动，例如一个三角形类会转型成为图形类，这种转型是可以默认执行的，即在任何条件下都能执行，同样，因为Java内所有的类都继承自Object，所以所有类都可以转型成为Object类。但是执行向上转型会丢失类的类型信息。 同样的还有向下转型：在继承树上向下移动，向下转型会用在已经使用过向上转型丢失了类型信息的类，即将从三角形类转换为图形类的类转回三角形类。具体方法类似于强制转换，在需要转换的类前Object b =（Object）a：将转换后的类重新引用。 协变返回类型​ 这个概念的解释在《Think in Java》一书中是这样的：协变返回类型表示在导出类中的被覆盖方法可以返回基类方法返回的某种类型的某种导出类型。这句话的大概意思是A继承B，C继承D，C的方法返回A，现在D的覆盖C的方法可以返回B，这是在Java SE5中的一个更新。 查看更多Java基础：Java基础","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"基础","slug":"基础","permalink":"http://yoursite.com/tags/基础/"}]},{"title":"Ubuntu环境系统搭建","slug":"Ubuntu环境系统搭建","date":"2018-03-08T08:37:05.000Z","updated":"2018-07-15T06:35:05.894Z","comments":true,"path":"2018/03/08/Ubuntu环境系统搭建/","link":"","permalink":"http://yoursite.com/2018/03/08/Ubuntu环境系统搭建/","excerpt":"","text":"Ubuntu环境系统搭建​ 昨天下午，想在Ubuntu系统上安装一个便签的应用，结果发现所有的源不能够更新，查了一下，发现官方已经停止对Ubuntu17.04进行维护，然后可以更新到17.10版本，就更新了一下系统。中途因误操作关掉了更新进程，系统崩溃，然后重新刷了一下16.04LTS，升级到了17.10.所有环境和配置丢失，重新开始配环境，记录一下搭建的环境及步骤。 删除OpenJDK并安装OracleJDK​ Ubuntu17.10自带的JDK版本是openjdk，所以删除，安装OracleJDK。 删除默认JDK123sudo apt-get install default-jdk sudo apt-get autoremove default-jdk sudo apt-get autoremove openjdk* 安装OracleJDK12345678910111213解压下载好的JDK9，移动到文件夹sudo mkdir /usr/javasudo mv jdk-9.0.4 /usr/java配置环境变量：sudo gedit /etc/environment在末尾添加PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:$JAVA_HOME/bin&quot;export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/libexport JAVA_HOME=/usr/java/jdk-9.0.4保存，输入命令：source /etc/environment输入测试命令：java -version 安装vim​ 全新的17.10并没有内置vim,所以需要自己安装vim 1sudo apt-get install vim 安装LAMP环境安装apache1sudo apt-get install apache2 安装mysql1sudo apt-get install mysql-server（中间设置密码） 安装PHP1sudo apt-get install php7.1 php7.1-dev 重启apache1sudo /etc/init.d/apache restart (在http://localhost/ 检查apache运行) php探针12sudo vim /var/www/html/info.phpinfo.php: &lt;?php phpinfo(); 安装phpmyadmin1234567891011sudo apt-get install phpmyadminsudo apt-get install php-mbstringsudo apt-get install php-gettext建立软连接sudo ln -s /usr/share/phpmyadmin /var/www/html/phpmyadminnano /etc/php/7.0/apache2/php.ini配置phpmyadmindisplay_errors = Onextension=php_mbstring.dll重启apache打开 localhost/phpmyadmin/测试，成功 安装Tomcat12sudo apt-get install tomcat8apt-get install tomcat8-docs tomcat8-examples tomcat8-admin 安装IDEA123在官网下载idea的tar.gz包，解压并且移动到文件夹cd /binsh ./idea.sh 安装HEXO安装Nodejs生成静态页面12sudo apt-get install nodejssudo apt-get install npm 安装Hexo并执行初始化12345sudo npm install -g hexohexo init &lt;d&gt;cd &lt;d&gt;npm install hexo -v Hexo命令1234hexo clean #清除数据hexo g(generate) #生成静态网页hexo s(server) #运行本地服务器hexo d(deploy) #推送数据到git仓库 安装配置github1234567sudo apt-get install git输入配置github，否则推送会报错未有合适地址git config --global user.name &quot;yourName&quot;git config --global user.eamil &quot;eamil@eamil.com&quot;创建公钥ssh-keygen -C &apos;you eamil@eamil.com&apos; -t rsa打开~/.ssh/id_rsa.pub 文件查看生成的公钥，并且将其复制到github的setting中的ssh keys 配置Hexo部署到github12345678sudo gedit _config.yml在内容的最后修改：deploy: type: git repository: https://github.com/tofulife/tofulife.github.io.git branch: master保存退出，并在终端输入npm install hexo-deployer-git --save Hexo在文章中插入图片123456打开hexo文件夹下的_config.ymlsudo gedit _config.yml开启设置： post_asset_folder:ture开启后，新建文章会建立同名文件夹。 保存退出，并在终端输入npm install https://github.com/CodeFalling/hexo-asset-image --save在文章中，添加 ![logo](/文件夹名字/图片名字.jpg) 可插入图片 使用Hexo推送文章123hexo cleanhexo ghexo s 安装搜狗输入法​ 搜狗输入法在Ubuntu上面可以说是非常人性化了，哪怕是17.10，直接到搜狗输入的官方网站下载deb包，然后在软件中心安装。 安装网易云音乐​ 无音乐，不代码。一个充满音乐质感的环境对于提升工作效率有极大的帮助，但是安装网易云音乐在17.10并不是一个愉快的体验。 网易云官网上有关于netease-music for linux 的deb包，版本号为V1.1.0，位数为64位。直接下载安装。通过在软件库里打开图标会出现错误，桌面缓冲10s左右，退出，我没有打开进程查看，但是网络上的解释里面有反应存在网易云音乐的进程。解决方案在网易云音乐V1.0.1版本的时候通过在/usr/share/applications/netease-cloud-music.desktop修改命令参数，能够正常使用。V1.1.0版本此方法失效，可行的两个解决方案： 1234gksu netease-cloud-music %U通过命令开启网易云音乐，然后这个命令打开后可以关闭Ctrl+C关闭进程，网易云正常使用。sudo netease-cloud-music必须使用root命令，开启后进程不能够关闭，才能够正常使用。 另外还看到了一种解决方案，但是我的电脑上并没有成功，也可以尝试一下： 123sudo gedit /usr/share/applications/netease-cloud-music.desktop在打开的文档里面，将Terminal=false这一行移动到EXec=netease-cloud-music %U 这一行上面有说这种方法成功的，但是我并没有成功。 安装Numix主题12345sudo add-apt-repository ppa:numix/ppasudo apt-get updatesudo apt-get install numix-gtk-theme numix-icon-theme-circle安装Gnome Tweak Tool 来修改主题和图标sudo apt-get install gnome-tweak-tool","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://yoursite.com/tags/Ubuntu/"},{"name":"系统搭建","slug":"系统搭建","permalink":"http://yoursite.com/tags/系统搭建/"}]},{"title":"Java的复用","slug":"Java的复用","date":"2018-03-08T06:36:29.000Z","updated":"2018-07-15T07:26:56.046Z","comments":true,"path":"2018/03/08/Java的复用/","link":"","permalink":"http://yoursite.com/2018/03/08/Java的复用/","excerpt":"Java的复用原文","text":"Java的复用原文 继承​ 继承更为确切的说，继承树上下两个节点之间（即基类和导出类）的关系属于is-a的关系。 导出类（子类）使用 extends 从基类（父类）进行继承，导出类会继承父类中的public或是protected的方法或是属性。同时，导出类可以对这些方法或是属性进行重写。 初始化：对于基类和子类，使用构造器进行初始化，初始化过程是从基类开始扩展，及先基类在第一代子类然后第二代子类（初始化过程即构造函数链）。 当不存在基类构造器或者想要调用带参数的构造器，使用super 显式的编写调用基类构造器的语句。 可以使用super()显式调用父类的构造器，如果没有显式的调用，编译器会默认调用。当在构造器内显式调用父类的构造器的时候，super()必须是构造器的第一个命令。 ​ 初始化的实际过程： 1234在其他任何事物发生之前，将分配给对象的存储空间初始化为二进制的零。调用基类构造器。按照声明的顺序调用成员的初始化方法。调用导出类的构造器主体。 &nbsp;&nbsp;&nbsp;&nbsp;继承，继承的是基类的接口。在继承的时候，使用某个现有类，并且开发一个它的特殊版本。换而言之，继承的作用是我需要将一个通用的类特例化，例如我需要汽车，汽车可以从交通工具特例化，这就是继承。 在继承中，当子类需要使用基类的方法时候，使用super调用基类的方法。 在Java继承时，程序代码会将导出类的引用转换为基类的引用，这种现象称为 向上转型。向上转型是从一个较专用类型向较通用类型转换，所以向上转型总是很安全的。或者说，导出类是基类的一个超集，导出类可以含有比基类更多的方法，但是它必须至少含有基类中所含有的方法。 纯继承：继承时只对基类的方法进行覆盖，而不对导出类进行任何扩展。 ​ 多重继承（Java已经取消）：将一个类继承自多个类。 存在缺点：当继承的这些基类有着一个共同名称的方法，但是方法执行是不同的，当导出类实现这个方法时候，就会造成混乱。所以Java引入接口来解决这个问题，因为一个类可以继承多个接口。 组合​ 组合是将一个对象引用置于新对象。也就是在一个新的对象内使用一个对象。 组合技术通常是想在新类中使用现有类的功能而非它的接口。即，在现有类中嵌入一个对象，让其实现所具有的功能，在新类的用户只能看到为新类所定义的接口，而非嵌入对象的接口。换而言之，我想要在汽车这个类内使用轮子、发动机两个对象，而当我将发动机和轮子装到汽车这个类时，这便成为了汽车所具有的特殊结构，所以我需要将发动机和轮子具有的属性或是方法用汽车的方式重新定义。 代理​ 代理，是介于继承和组合中间的一个方法。代理将一个对象置于要构造的类内部，但是同时将这个对象的所有方法暴露在新类里面。换句话讲，在新类内部使用原类抽象的对象，新建同名的方法，返回为对象的方法。也就是将当前对象的方法返回新类的方法。 查看更多Java基础：Java基础","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"基础","slug":"基础","permalink":"http://yoursite.com/tags/基础/"}]},{"title":"Java控制执行流程","slug":"Java控制执行流程","date":"2018-03-08T06:36:19.000Z","updated":"2018-07-15T07:26:46.330Z","comments":true,"path":"2018/03/08/Java控制执行流程/","link":"","permalink":"http://yoursite.com/2018/03/08/Java控制执行流程/","excerpt":"Java控制执行流程原文","text":"Java控制执行流程原文 1、if 语句：if语句类似于c++ 及 JavaScript 12if （boolean-expression) statement else statement 2、迭代循环语句： while 语句： 12while (boolean-expression) satement ​ do while 语句： 12do statement while (boolean-expression); ​ for 语句： 12for (initialization; boolean-expression; step) statement ​ for each 语句：不必创建int变量去对由访问项构成的序列进行计数，foreach将产生每一项。换而言之，foreach将会自动遍历当前循环内全部的元素。 for ( float x : f ) 定义一个float类型的变量x，将每一个 f 的元素赋值给x。 3、return ： 从当前语句内返回一个值。 break：结束当前循环，返回上一层循环。 continue：跳过这一次的循环，开始下一次的循环。4、switch：选择语句，根据获得的表达式的值，从所有代码中选择一个去执行。 在switch 语句内，可以使用枚举类型 enum 。5、goto ：臭名昭著的 goto。goto的实际是对条件进行判断，并且根据判断结果选择程序跳到哪个位置进行执行。原为汇编语言内的机制。 Java取消了goto，仅把goto作为保留字。但是在控制循环流程内，Java使用了标签机制，进行程序的跳转。 label: 标签常跟break或者continue连用，表示中断当前循环，直到标签所在的位置。 查看更多Java基础：Java基础","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"基础","slug":"基础","permalink":"http://yoursite.com/tags/基础/"}]},{"title":"Java访问控制","slug":"Java访问控制","date":"2018-03-08T06:36:13.000Z","updated":"2018-07-15T07:26:24.470Z","comments":true,"path":"2018/03/08/Java访问控制/","link":"","permalink":"http://yoursite.com/2018/03/08/Java访问控制/","excerpt":"Java访问控制原文","text":"Java访问控制原文 ​ Java内的访问控制权限有四种：public 、default、 protected 、private。权限等级依次降低。 123将方法或者是属性定义为public：意味着这个方法或者属性对其他的类（所有的类）是可以访问的。将方法或者是属性定义为protected：意味着这个方法或者属性只是对当前类的导出类或是同一个包内的类来说是可以进行访问的，protected 具有包内访问权限。将方法或者是属性定义为private：这意味着这个方法或者属性只是对于当前定义它的类来说是可以访问的，除此之外，任何类都不能访问。 ​ 包内访问权限：当定义为public或protected时候，当前这个方法或是属性对位于同一个包内部的类来说是可以访问的。 当一个方法没有定义控制权限的时候，将会默认定义为包访问权限。 补充​ 一个非内部类只能是Public或者默认包访问权限的，内部类可以拥有private或者protected的访问权限。通常的访问权限对类内部的成员，即方法、变量而言的。 查看更多Java基础：Java基础","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"基础","slug":"基础","permalink":"http://yoursite.com/tags/基础/"}]},{"title":"Java基础","slug":"Java基础","date":"2018-03-08T06:35:52.000Z","updated":"2018-07-15T07:03:45.658Z","comments":true,"path":"2018/03/08/Java基础/","link":"","permalink":"http://yoursite.com/2018/03/08/Java基础/","excerpt":"","text":"Java基础整理好的Java基础博文​ Java控制执行流程：Java控制执行流程 Java的特殊关键字:Java的特殊关键字 Java访问控制：Java访问控制 接口和抽象类：接口和抽象类 Java多态：Java的特性-多态 Java复用：Java的复用","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"基础","slug":"基础","permalink":"http://yoursite.com/tags/基础/"}]},{"title":"数据库数据模型","slug":"数据库数据模型","date":"2018-03-06T08:41:57.000Z","updated":"2018-07-15T07:26:04.302Z","comments":true,"path":"2018/03/06/数据库数据模型/","link":"","permalink":"http://yoursite.com/2018/03/06/数据库数据模型/","excerpt":"&nbsp;&nbsp;&nbsp;&nbsp;在去年学习数据库原理的时候,就听老师讲过数据模型,层次模型、网状模型、关系模型，这样一些数据模型，当时不懂数据结构，所以哪怕当时老师讲的再清楚，过后没多久也就都忘记了。&nbsp;&nbsp;&nbsp;&nbsp;恰巧今天在看一本书的时候，看到了这么一句话：“在关系模型中，可以使用高级的程序语言，如SQL，使得开发者能够在较高的层次上进行开发。很少的SQL语句就可以完成数千行C代码才能完成的工作，或者是数百行网状模型或层次模型才能完成的数据访问工作。”然后对，文章中提到的两种模型感兴趣了，就搜集资料学习了一下。","text":"&nbsp;&nbsp;&nbsp;&nbsp;在去年学习数据库原理的时候,就听老师讲过数据模型,层次模型、网状模型、关系模型，这样一些数据模型，当时不懂数据结构，所以哪怕当时老师讲的再清楚，过后没多久也就都忘记了。&nbsp;&nbsp;&nbsp;&nbsp;恰巧今天在看一本书的时候，看到了这么一句话：“在关系模型中，可以使用高级的程序语言，如SQL，使得开发者能够在较高的层次上进行开发。很少的SQL语句就可以完成数千行C代码才能完成的工作，或者是数百行网状模型或层次模型才能完成的数据访问工作。”然后对，文章中提到的两种模型感兴趣了，就搜集资料学习了一下。 &nbsp;&nbsp;&nbsp;&nbsp;层次模型&nbsp;&nbsp;&nbsp;&nbsp;用一颗“有向树”的数据结构来表示各类实体及实体间的联系，树中每一个节点代表一个记录类型，树状结构表示实体型间的联系。&nbsp;&nbsp;&nbsp;&nbsp;这是来自百度的解释。字面意思，很容易理解，层次模型就是一颗树，用树枝来标示关系，用叶或枝干标示数据。从程序人的角度看，结构非常的简单，数据的查询操作就是树的查询操作，模型的结构通过结点的双亲就能推出。复杂或者说影响大的是插入删除操作，在大量的数据请求中，效率很低，另外对于多对多关系和多对一关系不好描述。 &nbsp;&nbsp;&nbsp;&nbsp;网状模型&nbsp;&nbsp;&nbsp;&nbsp;一个事物和另外的几个都有联系，这样构成一张网状图。&nbsp;&nbsp;&nbsp;&nbsp;看到这个描述，我最先想到的就是现在正处于风口的区块链技术，虽然一个是基于网状网络，而另一个是数据实体间的网状模型，但是两种构成基础相同：基于数据结构中的图，更加容易的描述出不同实体之间的非层次关系，例如多对一关系和多对多关系。&nbsp;&nbsp;&nbsp;&nbsp;但是基于图创建的P2P网状网络，或是流行的区块链技术，或是数据的网状模型，都在本身有一个弊端：结构的复杂性。这种复杂性导致了网状结构的复杂性，不易实现。 &nbsp;&nbsp;&nbsp;&nbsp;关系模型&nbsp;&nbsp;&nbsp;&nbsp;前面说了这么多，我也只是为了给关系模型做铺垫而已（偷乐）。&nbsp;&nbsp;&nbsp;&nbsp;关系模型通过一个关系的二维表给出描述。表，一种按照顺序排列的数据集合，在这个结构里面，每个表表示一个实体，实体之间的关系，通过表之间的关系或者关联表给出，相较于层次结构有了极大的优化。&nbsp;&nbsp;&nbsp;&nbsp;在关系模型中，关系模式=关系名+属性集合的组合。关系的元组之间具有无序性，可以通过某一个“属性”来标识顺序关系，同样的，关系数据库的数据搜索就成了一个可以加深研究的方面。&nbsp;&nbsp;&nbsp;&nbsp;关系并不是静态的，在关系模型里面，关系模式是静态的，但是关系是动态的，通过操作不断的更新数据库，这也就为开发维护带来了极大的方便。 &nbsp;&nbsp;&nbsp;&nbsp;半结构化模型&nbsp;&nbsp;&nbsp;&nbsp;除去关系模型在当今数据库系统中大范围应用外，还有一种独特的关系模型：半结构化数据模型。&nbsp;&nbsp;&nbsp;&nbsp;这种模型，我了解到的就是XML和HTML这两种文档使用，具体结构的详细信息我会在单独了解后再整理。","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]},{"title":"博客！博客！","slug":"我的博客","date":"2018-03-05T07:29:31.000Z","updated":"2018-03-06T03:38:29.000Z","comments":true,"path":"2018/03/05/我的博客/","link":"","permalink":"http://yoursite.com/2018/03/05/我的博客/","excerpt":"","text":"&nbsp;&nbsp;终于决定写个人博客了！！！ &nbsp;&nbsp;&nbsp;&nbsp;大一的时候在CSDN上写过一段时间的ACM题目解析，时间不长，一个学期。 &nbsp;&nbsp;&nbsp;&nbsp;去年开始尝试写个人笔记，我记得最先使用的是印象笔记，当时确实是把它当成了一个在线笔记使用，记录的多是学习过程的重要点或者知识点，写过段时间也就没在写，单纯的记录知识点跟看书没什么区别。 &nbsp;&nbsp;&nbsp;&nbsp;这之后准备正式的写一些个人博客，开始的时候，自己做一个网站，计划做成一个动态的网站，问题来了：前后端不兼容（拙劣的审美让我放弃了前台自己做的想法）、数据库不稳定、写文章的功能不完善（我尝试过一些流行的Editor）。发生了好多问题之后，我开始在简书上写一些个人的感想或是杂谈，是的，我放弃了这个让人热血澎湃的想法。 &nbsp;&nbsp;&nbsp;&nbsp;然后这个学期开学，做一个个人博客的想法又开始萌发，考虑了一下，把博客挂到github上，然后做了这么一个简易的博客。 &nbsp;&nbsp;&nbsp;&nbsp;我会在后面一些的日子里，把我以前写过的一些文章整理发布到这个博客上来。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Hello World！ I’m coming!","categories":[],"tags":[{"name":"杂记","slug":"杂记","permalink":"http://yoursite.com/tags/杂记/"},{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]},{"title":"Java的特殊关键字","slug":"Java的特殊关键字","date":"2017-12-09T06:36:43.000Z","updated":"2018-07-15T07:27:10.138Z","comments":true,"path":"2017/12/09/Java的特殊关键字/","link":"","permalink":"http://yoursite.com/2017/12/09/Java的特殊关键字/","excerpt":"Java的特殊关键字this关键字​ this关键字this关键字代表的含义是在方法内部使用，表示对调用这个方法的对象的自身的引用。也就是说，调用this的方法，最终会返回当前对象。当参数名字和数据成员名字相同时候，可以用 this.dataname 来表示数据成员。","text":"Java的特殊关键字this关键字​ this关键字this关键字代表的含义是在方法内部使用，表示对调用这个方法的对象的自身的引用。也就是说，调用this的方法，最终会返回当前对象。当参数名字和数据成员名字相同时候，可以用 this.dataname 来表示数据成员。 final关键字​ 在Java中使用final关键字的两种优点： 将方法定义为final，可以有效的关闭动态绑定，即编译器不需要对其进行绑定，可以对final方法调用生成更有效的代码。 禁止在继承中覆盖方法。如果一个final方法在类中被重载，并且这个重载后的方法不再是final，那么这个重载方法是能够继承覆盖的，因为其相当于一个新的方法。 12345678910111213final 数据： 将基本类型设置为final 数值和引用都是恒定不变的。 带有恒定初始值（编译器常量）的final static 基本类型全用大写字母命名，并且字与字之间用下划线隔开。空白 final： 空白final 指被声明为final 但未给定初始值的域。final 参数： 在参数列表中以声明的方式将参数声明为final ，意味着不能在方法中更改参数引用所指定的对象。 这也就意味着可以读取参数，但是不能修改参数。这个特性用来向匿名内部类传递数据。 这意味着这个参数是常量。final 方法： 将方法定义为 final ，将会把方法锁定，防止任何继承类修改它的含义，确保继承中使方法保持不变，并且不会被覆盖。 类中的所有的private方法都被隐式的定义为final。final 类： 将一个类定义为final类的时候，将不允许该类被任何类继承。指定的final类中的所有方法都会被隐性的指定为final。String类被final修饰。 Static关键字​ static ：创建一个固定的区域，用以存放对象。定义方式：将static关键字放到定义之前，将字段或是方法设为static。 1234567static对象：可以参考JavaScript内的原型对象，使用static创建一个类，然后用这个类去创建对象，所有的对象只有一个副本，对象之间对于创建的实例类来说是共享的，不是类似于普通类，创建一个对象就有一个副本。 static方法：static方法的一个重要用法就是在不创建任何对象的前提下就能够调用这个方法。static方法同样可以创建或使用与其类型相同的被命名对象。 static 方法不含this方法。 static方法的调用，使用类的名称去调用，而不是像非静态方法，使用类的对象的引用变量的名称去调用。 静态的方法不能够调用非静态的变量，同样也不能够调用非静态的方法。调用非静态的方法或变量的方式就是创建实例，通过实例去调用。static变量：值是固定的，对于所有的实例变量来说都是相同的。静态变量会在类执行任何静态方法之前就被初始化。 静态变量是共享的，一个类所有的实例对象共享一份静态变量。 ​ static关键字修饰的成员，相当于与这个类做一个绑定，而不是与生成的对象做绑定，所以static修饰的方法将不能够进行动态绑定。 查看更多Java基础：Java基础","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"基础","slug":"基础","permalink":"http://yoursite.com/tags/基础/"}]}]}